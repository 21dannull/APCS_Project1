{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Rainbow_DQN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWnqUnPLk9zE"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Softmax\n",
        "import random\n",
        "import numpy as np\n",
        "import gym\n",
        "import math\n",
        "import copy\n",
        "from collections import deque\n",
        "from matplotlib import pyplot as plt\n",
        "#!pip install box2d"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mT18K1P9gWL1"
      },
      "source": [
        "class ReplayBuffer:\n",
        "\n",
        "  def __init__(self, n=1, max_size=1_000_000):\n",
        "    self.buffer = []\n",
        "    self.max_size = max_size\n",
        "    self.n = n\n",
        "    self.ctr = 0\n",
        "    self.filled = False\n",
        "  \n",
        "  def add(self, s, a, r, s1, d):\n",
        "    if not self.filled:\n",
        "      self.buffer.append((s, a, r, s1, d))\n",
        "      if self.ctr == self.max_size - 1:\n",
        "        self.filled = True\n",
        "    else:\n",
        "      if self.ctr == self.max_size:\n",
        "        self.ctr = 0\n",
        "      self.buffer[self.ctr] = (s, a, r, s1, d)\n",
        "    self.ctr += 1\n",
        "    \n",
        "  def sample(self, batch_size):\n",
        "    if len(self.buffer) < batch_size:\n",
        "      return self.buffer\n",
        "    else:\n",
        "      return random.sample(self.buffer, batch_size)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3m07EGRwVcq"
      },
      "source": [
        "class DQN:\n",
        "\n",
        "  def __init__(self, env, opt=None, loss=None, epsilon_init=1, \n",
        "               epsilon_decay=0.995, epsilon_min=0.1, multiply_epsilon=True, batch_size=32,\n",
        "               buffer_length=1_000_000, gamma=0.95, model=None, double=False,\n",
        "               update_freq=None, noisy=False, distributional=False, z=None,\n",
        "               v_min=None, v_max=None, n_atoms=None, n_step=1):\n",
        "    self.env = env\n",
        "    self.obs_dim = env.observation_space.shape\n",
        "    self.act_dim = env.action_space.n\n",
        "    self.epsilon = epsilon_init\n",
        "    self.epsilon_decay = epsilon_decay\n",
        "    self.epsilon_min = epsilon_min\n",
        "    self.model = self.build_model(model)\n",
        "    self.buffer = ReplayBuffer(max_size=buffer_length, n=n_step)\n",
        "    self.batch_size = batch_size\n",
        "    self.gamma = gamma\n",
        "    self.double = double\n",
        "    self.noisy = noisy\n",
        "    self.distributional = distributional\n",
        "    self.n_step = n_step\n",
        "    self.multiply_epsilon = multiply_epsilon\n",
        "\n",
        "    if opt is None:\n",
        "      self.optimizer = tf.keras.optimizers.Adam()\n",
        "    else:\n",
        "      self.optimizer = opt\n",
        "\n",
        "    if loss is None:\n",
        "      self.loss = tf.keras.losses.MSE\n",
        "    else:\n",
        "      self.loss = loss\n",
        "\n",
        "    if double:\n",
        "      self.target_model = self.build_model(model)\n",
        "      assert (update_freq is not None)\n",
        "      self.update_freq = update_freq\n",
        "    \n",
        "    if distributional:\n",
        "      assert (z is not None)\n",
        "      assert (v_min is not None)\n",
        "      assert (v_max is not None)\n",
        "      assert (n_atoms is not None)\n",
        "      self.z = z\n",
        "      self.v_min = v_min\n",
        "      self.v_max = v_max\n",
        "      self.n_atoms = n_atoms\n",
        "      self.dz = (self.v_max - self.v_min) / (self.n_atoms - 1)\n",
        "  \n",
        "  def build_model(self, model):\n",
        "    if model is None:\n",
        "      inp = tf.keras.Input(self.obs_dim)\n",
        "      x = Dense(24, activation=\"relu\")(inp)\n",
        "      x = Dense(24, activation=\"relu\")(x)\n",
        "      out = Dense(self.act_dim)(x)\n",
        "      return tf.keras.Model(inputs=inp, outputs=out)\n",
        "    else:\n",
        "      return model\n",
        "  \n",
        "  def act(self, x, decay=True):\n",
        "    if self.noisy:\n",
        "      return np.argmax(np.squeeze(self.model(x.reshape(1, 4)).numpy()))\n",
        "    else:\n",
        "      if np.random.random() < self.epsilon:\n",
        "        if decay:\n",
        "          self.decay_epsilon()\n",
        "        return random.randrange(self.act_dim)\n",
        "      else:\n",
        "        if decay:\n",
        "          self.decay_epsilon()\n",
        "        if self.distributional:\n",
        "          out = np.vstack(self.model(x.reshape((1, 4))))\n",
        "          q = np.sum(np.multiply(out, self.z), axis=1)\n",
        "          return np.argmax(q)\n",
        "        else:\n",
        "          return np.argmax(np.squeeze(self.model(x[np.newaxis, :]).numpy()))\n",
        "\n",
        "  def decay_epsilon(self):\n",
        "    if self.multiply_epsilon:\n",
        "      self.epsilon *= self.epsilon_decay\n",
        "    else:\n",
        "      self.epsilon -= self.epsilon_decay\n",
        "    self.epsilon = max(self.epsilon, self.epsilon_min)\n",
        "  \n",
        "  def backward(self, x, y, actions):\n",
        "    if self.distributional:\n",
        "      with tf.GradientTape() as tape:\n",
        "        loss = self.loss(tf.stop_gradient(y), self.model(x))\n",
        "      grad = tape.gradient(loss, self.model.trainable_weights)\n",
        "      self.optimizer.apply_gradients(zip(grad, self.model.trainable_weights))\n",
        "    else:\n",
        "      with tf.GradientTape() as tape:\n",
        "        loss = self.loss(tf.stop_gradient(y), tf.reduce_sum(\n",
        "            self.model(x) * actions, axis=1))\n",
        "      grad = tape.gradient(loss, self.model.trainable_weights)\n",
        "      self.optimizer.apply_gradients(zip(grad, self.model.trainable_weights))\n",
        "  \n",
        "  def update_target(self):\n",
        "    self.target_model.set_weights(self.model.get_weights())\n",
        "  \n",
        "  def train(self, games):\n",
        "    reward_list = []\n",
        "    total_steps = 0\n",
        "    for game in range(games):\n",
        "      s = self.env.reset()\n",
        "      step_ctr = 0\n",
        "      d = False\n",
        "      game_reward = 0\n",
        "      while not d:\n",
        "        if self.double and (total_steps == self.update_freq):\n",
        "          self.update_target()\n",
        "          total_steps = 0\n",
        "        if self.noisy:\n",
        "          for layer in self.model.layers:\n",
        "            if isinstance(layer, NoisyDense):\n",
        "              layer.unfreeze_epsilon()\n",
        "        a = self.act(s)\n",
        "        if self.noisy:\n",
        "          for layer in self.model.layers:\n",
        "            if isinstance(layer, NoisyDense):\n",
        "              layer.freeze_epsilon()\n",
        "        s1, r, d, _ = self.env.step(a)\n",
        "        game_reward += r\n",
        "        self.buffer.add(s, a, r, s1, d)\n",
        "        s = s1\n",
        "        s1 = None\n",
        "        \n",
        "        # Experience replay\n",
        "        exp = self.buffer.sample(self.batch_size)\n",
        "        states = np.array([i[0] for i in exp])\n",
        "        actions = np.array([i[1] for i in exp])\n",
        "        rewards = np.array([i[2] for i in exp])\n",
        "        nexts = np.array([i[3] for i in exp])\n",
        "        dones = np.array([i[4] for i in exp])\n",
        "        if self.distributional:\n",
        "          ### This implementation is from https://github.com/marload/DistRL-TensorFlow2/blob/master/C51/C51.py\n",
        "          z = self.model(nexts)\n",
        "          z_concat = np.vstack(z)\n",
        "          q = np.sum(np.multiply(z_concat, self.z), axis=1)\n",
        "          q = q.reshape((len(exp), self.act_dim), order=\"F\")\n",
        "          next_actions = np.argmax(q, axis=1)\n",
        "          m_prob = [np.zeros((len(exp), self.n_atoms)) for _ in range(self.act_dim)]\n",
        "          for i in range(len(exp)):\n",
        "            if dones[i]:\n",
        "              Tz = min(self.v_max, max(self.v_min, rewards[i]))\n",
        "              bj = (Tz - self.v_min) / self.dz\n",
        "              l, u = math.floor(bj), math.ceil(bj)\n",
        "              m_prob[actions[i]][i][int(l)] += (u - bj)\n",
        "              m_prob[actions[i]][i][int(u)] += (bj - l)\n",
        "            else:\n",
        "              for j in range(self.n_atoms):\n",
        "                Tz = min(self.v_max, max(self.v_min, rewards[i] + self.gamma * self.z[j]))\n",
        "                bj = (Tz - self.v_min) / self.dz\n",
        "                l, u = math.floor(bj), math.ceil(bj)\n",
        "                m_prob[actions[i]][i][int(l)] += z[next_actions[i]][i][j] * (u - bj)\n",
        "                m_prob[actions[i]][i][int(u)] += z[next_actions[i]][i][j] * (bj - l)\n",
        "          ###\n",
        "          z_cpy = [i.numpy() for i in z]\n",
        "          for i in range(len(exp)):\n",
        "            z_cpy[actions[i]][i] = m_prob[actions[i]][i]\n",
        "          self.backward(states, z_cpy, None)\n",
        "          \n",
        "        else:\n",
        "          if self.double:\n",
        "            target_q = self.target_model(nexts)\n",
        "          else:\n",
        "            target_q = self.model(nexts)\n",
        "          targets = rewards + tf.math.reduce_max(tf.transpose(tf.transpose(self.gamma * target_q) * (1 - dones)), axis=1)\n",
        "          one_hot = tf.one_hot(actions, self.act_dim)\n",
        "          self.backward(states, targets, one_hot)\n",
        "        step_ctr += 1\n",
        "        total_steps += 1\n",
        "      reward_list.append(game_reward)\n",
        "      print(\"Game: %d, Total Reward: %f, Epsilon: %f\" % (game + 1, game_reward, self.epsilon))\n",
        "    return reward_list"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6GOjIIsxFey",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3f074465-38da-4252-e6a9-6ac0837495d8"
      },
      "source": [
        "env = gym.make(\"CartPole-v1\")\n",
        "dqn = DQN(env)\n",
        "dqn.train(500)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Game: 1, Total Reward: 22.000000, Epsilon: 0.895587\n",
            "Game: 2, Total Reward: 14.000000, Epsilon: 0.834893\n",
            "Game: 3, Total Reward: 20.000000, Epsilon: 0.755253\n",
            "Game: 4, Total Reward: 24.000000, Epsilon: 0.669648\n",
            "Game: 5, Total Reward: 13.000000, Epsilon: 0.627403\n",
            "Game: 6, Total Reward: 14.000000, Epsilon: 0.584884\n",
            "Game: 7, Total Reward: 22.000000, Epsilon: 0.523814\n",
            "Game: 8, Total Reward: 15.000000, Epsilon: 0.485874\n",
            "Game: 9, Total Reward: 10.000000, Epsilon: 0.462120\n",
            "Game: 10, Total Reward: 10.000000, Epsilon: 0.439527\n",
            "Game: 11, Total Reward: 20.000000, Epsilon: 0.397600\n",
            "Game: 12, Total Reward: 11.000000, Epsilon: 0.376271\n",
            "Game: 13, Total Reward: 12.000000, Epsilon: 0.354305\n",
            "Game: 14, Total Reward: 11.000000, Epsilon: 0.335298\n",
            "Game: 15, Total Reward: 12.000000, Epsilon: 0.315725\n",
            "Game: 16, Total Reward: 8.000000, Epsilon: 0.303315\n",
            "Game: 17, Total Reward: 11.000000, Epsilon: 0.287043\n",
            "Game: 18, Total Reward: 10.000000, Epsilon: 0.273010\n",
            "Game: 19, Total Reward: 10.000000, Epsilon: 0.259662\n",
            "Game: 20, Total Reward: 14.000000, Epsilon: 0.242065\n",
            "Game: 21, Total Reward: 9.000000, Epsilon: 0.231387\n",
            "Game: 22, Total Reward: 10.000000, Epsilon: 0.220075\n",
            "Game: 23, Total Reward: 11.000000, Epsilon: 0.208269\n",
            "Game: 24, Total Reward: 11.000000, Epsilon: 0.197096\n",
            "Game: 25, Total Reward: 10.000000, Epsilon: 0.187460\n",
            "Game: 26, Total Reward: 9.000000, Epsilon: 0.179191\n",
            "Game: 27, Total Reward: 13.000000, Epsilon: 0.167887\n",
            "Game: 28, Total Reward: 9.000000, Epsilon: 0.160481\n",
            "Game: 29, Total Reward: 30.000000, Epsilon: 0.138076\n",
            "Game: 30, Total Reward: 147.000000, Epsilon: 0.100000\n",
            "Game: 31, Total Reward: 31.000000, Epsilon: 0.100000\n",
            "Game: 32, Total Reward: 225.000000, Epsilon: 0.100000\n",
            "Game: 33, Total Reward: 116.000000, Epsilon: 0.100000\n",
            "Game: 34, Total Reward: 112.000000, Epsilon: 0.100000\n",
            "Game: 35, Total Reward: 131.000000, Epsilon: 0.100000\n",
            "Game: 36, Total Reward: 60.000000, Epsilon: 0.100000\n",
            "Game: 37, Total Reward: 89.000000, Epsilon: 0.100000\n",
            "Game: 38, Total Reward: 54.000000, Epsilon: 0.100000\n",
            "Game: 39, Total Reward: 57.000000, Epsilon: 0.100000\n",
            "Game: 40, Total Reward: 73.000000, Epsilon: 0.100000\n",
            "Game: 41, Total Reward: 26.000000, Epsilon: 0.100000\n",
            "Game: 42, Total Reward: 19.000000, Epsilon: 0.100000\n",
            "Game: 43, Total Reward: 19.000000, Epsilon: 0.100000\n",
            "Game: 44, Total Reward: 38.000000, Epsilon: 0.100000\n",
            "Game: 45, Total Reward: 19.000000, Epsilon: 0.100000\n",
            "Game: 46, Total Reward: 90.000000, Epsilon: 0.100000\n",
            "Game: 47, Total Reward: 32.000000, Epsilon: 0.100000\n",
            "Game: 48, Total Reward: 113.000000, Epsilon: 0.100000\n",
            "Game: 49, Total Reward: 149.000000, Epsilon: 0.100000\n",
            "Game: 50, Total Reward: 116.000000, Epsilon: 0.100000\n",
            "Game: 51, Total Reward: 130.000000, Epsilon: 0.100000\n",
            "Game: 52, Total Reward: 138.000000, Epsilon: 0.100000\n",
            "Game: 53, Total Reward: 171.000000, Epsilon: 0.100000\n",
            "Game: 54, Total Reward: 278.000000, Epsilon: 0.100000\n",
            "Game: 55, Total Reward: 134.000000, Epsilon: 0.100000\n",
            "Game: 56, Total Reward: 246.000000, Epsilon: 0.100000\n",
            "Game: 57, Total Reward: 226.000000, Epsilon: 0.100000\n",
            "Game: 58, Total Reward: 196.000000, Epsilon: 0.100000\n",
            "Game: 59, Total Reward: 500.000000, Epsilon: 0.100000\n",
            "Game: 60, Total Reward: 255.000000, Epsilon: 0.100000\n",
            "Game: 61, Total Reward: 261.000000, Epsilon: 0.100000\n",
            "Game: 62, Total Reward: 201.000000, Epsilon: 0.100000\n",
            "Game: 63, Total Reward: 246.000000, Epsilon: 0.100000\n",
            "Game: 64, Total Reward: 167.000000, Epsilon: 0.100000\n",
            "Game: 65, Total Reward: 162.000000, Epsilon: 0.100000\n",
            "Game: 66, Total Reward: 215.000000, Epsilon: 0.100000\n",
            "Game: 67, Total Reward: 206.000000, Epsilon: 0.100000\n",
            "Game: 68, Total Reward: 199.000000, Epsilon: 0.100000\n",
            "Game: 69, Total Reward: 210.000000, Epsilon: 0.100000\n",
            "Game: 70, Total Reward: 213.000000, Epsilon: 0.100000\n",
            "Game: 71, Total Reward: 169.000000, Epsilon: 0.100000\n",
            "Game: 72, Total Reward: 201.000000, Epsilon: 0.100000\n",
            "Game: 73, Total Reward: 186.000000, Epsilon: 0.100000\n",
            "Game: 74, Total Reward: 180.000000, Epsilon: 0.100000\n",
            "Game: 75, Total Reward: 196.000000, Epsilon: 0.100000\n",
            "Game: 76, Total Reward: 178.000000, Epsilon: 0.100000\n",
            "Game: 77, Total Reward: 207.000000, Epsilon: 0.100000\n",
            "Game: 78, Total Reward: 206.000000, Epsilon: 0.100000\n",
            "Game: 79, Total Reward: 190.000000, Epsilon: 0.100000\n",
            "Game: 80, Total Reward: 178.000000, Epsilon: 0.100000\n",
            "Game: 81, Total Reward: 201.000000, Epsilon: 0.100000\n",
            "Game: 82, Total Reward: 221.000000, Epsilon: 0.100000\n",
            "Game: 83, Total Reward: 225.000000, Epsilon: 0.100000\n",
            "Game: 84, Total Reward: 191.000000, Epsilon: 0.100000\n",
            "Game: 85, Total Reward: 203.000000, Epsilon: 0.100000\n",
            "Game: 86, Total Reward: 230.000000, Epsilon: 0.100000\n",
            "Game: 87, Total Reward: 192.000000, Epsilon: 0.100000\n",
            "Game: 88, Total Reward: 190.000000, Epsilon: 0.100000\n",
            "Game: 89, Total Reward: 201.000000, Epsilon: 0.100000\n",
            "Game: 90, Total Reward: 175.000000, Epsilon: 0.100000\n",
            "Game: 91, Total Reward: 203.000000, Epsilon: 0.100000\n",
            "Game: 92, Total Reward: 182.000000, Epsilon: 0.100000\n",
            "Game: 93, Total Reward: 179.000000, Epsilon: 0.100000\n",
            "Game: 94, Total Reward: 170.000000, Epsilon: 0.100000\n",
            "Game: 95, Total Reward: 208.000000, Epsilon: 0.100000\n",
            "Game: 96, Total Reward: 253.000000, Epsilon: 0.100000\n",
            "Game: 97, Total Reward: 234.000000, Epsilon: 0.100000\n",
            "Game: 98, Total Reward: 201.000000, Epsilon: 0.100000\n",
            "Game: 99, Total Reward: 215.000000, Epsilon: 0.100000\n",
            "Game: 100, Total Reward: 206.000000, Epsilon: 0.100000\n",
            "Game: 101, Total Reward: 211.000000, Epsilon: 0.100000\n",
            "Game: 102, Total Reward: 181.000000, Epsilon: 0.100000\n",
            "Game: 103, Total Reward: 210.000000, Epsilon: 0.100000\n",
            "Game: 104, Total Reward: 237.000000, Epsilon: 0.100000\n",
            "Game: 105, Total Reward: 224.000000, Epsilon: 0.100000\n",
            "Game: 106, Total Reward: 235.000000, Epsilon: 0.100000\n",
            "Game: 107, Total Reward: 197.000000, Epsilon: 0.100000\n",
            "Game: 108, Total Reward: 230.000000, Epsilon: 0.100000\n",
            "Game: 109, Total Reward: 203.000000, Epsilon: 0.100000\n",
            "Game: 110, Total Reward: 229.000000, Epsilon: 0.100000\n",
            "Game: 111, Total Reward: 242.000000, Epsilon: 0.100000\n",
            "Game: 112, Total Reward: 211.000000, Epsilon: 0.100000\n",
            "Game: 113, Total Reward: 212.000000, Epsilon: 0.100000\n",
            "Game: 114, Total Reward: 205.000000, Epsilon: 0.100000\n",
            "Game: 115, Total Reward: 231.000000, Epsilon: 0.100000\n",
            "Game: 116, Total Reward: 179.000000, Epsilon: 0.100000\n",
            "Game: 117, Total Reward: 178.000000, Epsilon: 0.100000\n",
            "Game: 118, Total Reward: 209.000000, Epsilon: 0.100000\n",
            "Game: 119, Total Reward: 201.000000, Epsilon: 0.100000\n",
            "Game: 120, Total Reward: 204.000000, Epsilon: 0.100000\n",
            "Game: 121, Total Reward: 269.000000, Epsilon: 0.100000\n",
            "Game: 122, Total Reward: 235.000000, Epsilon: 0.100000\n",
            "Game: 123, Total Reward: 255.000000, Epsilon: 0.100000\n",
            "Game: 124, Total Reward: 237.000000, Epsilon: 0.100000\n",
            "Game: 125, Total Reward: 196.000000, Epsilon: 0.100000\n",
            "Game: 126, Total Reward: 176.000000, Epsilon: 0.100000\n",
            "Game: 127, Total Reward: 193.000000, Epsilon: 0.100000\n",
            "Game: 128, Total Reward: 203.000000, Epsilon: 0.100000\n",
            "Game: 129, Total Reward: 282.000000, Epsilon: 0.100000\n",
            "Game: 130, Total Reward: 200.000000, Epsilon: 0.100000\n",
            "Game: 131, Total Reward: 235.000000, Epsilon: 0.100000\n",
            "Game: 132, Total Reward: 167.000000, Epsilon: 0.100000\n",
            "Game: 133, Total Reward: 170.000000, Epsilon: 0.100000\n",
            "Game: 134, Total Reward: 216.000000, Epsilon: 0.100000\n",
            "Game: 135, Total Reward: 191.000000, Epsilon: 0.100000\n",
            "Game: 136, Total Reward: 173.000000, Epsilon: 0.100000\n",
            "Game: 137, Total Reward: 189.000000, Epsilon: 0.100000\n",
            "Game: 138, Total Reward: 173.000000, Epsilon: 0.100000\n",
            "Game: 139, Total Reward: 176.000000, Epsilon: 0.100000\n",
            "Game: 140, Total Reward: 201.000000, Epsilon: 0.100000\n",
            "Game: 141, Total Reward: 199.000000, Epsilon: 0.100000\n",
            "Game: 142, Total Reward: 216.000000, Epsilon: 0.100000\n",
            "Game: 143, Total Reward: 207.000000, Epsilon: 0.100000\n",
            "Game: 144, Total Reward: 173.000000, Epsilon: 0.100000\n",
            "Game: 145, Total Reward: 185.000000, Epsilon: 0.100000\n",
            "Game: 146, Total Reward: 199.000000, Epsilon: 0.100000\n",
            "Game: 147, Total Reward: 211.000000, Epsilon: 0.100000\n",
            "Game: 148, Total Reward: 201.000000, Epsilon: 0.100000\n",
            "Game: 149, Total Reward: 206.000000, Epsilon: 0.100000\n",
            "Game: 150, Total Reward: 167.000000, Epsilon: 0.100000\n",
            "Game: 151, Total Reward: 218.000000, Epsilon: 0.100000\n",
            "Game: 152, Total Reward: 224.000000, Epsilon: 0.100000\n",
            "Game: 153, Total Reward: 181.000000, Epsilon: 0.100000\n",
            "Game: 154, Total Reward: 222.000000, Epsilon: 0.100000\n",
            "Game: 155, Total Reward: 210.000000, Epsilon: 0.100000\n",
            "Game: 156, Total Reward: 194.000000, Epsilon: 0.100000\n",
            "Game: 157, Total Reward: 189.000000, Epsilon: 0.100000\n",
            "Game: 158, Total Reward: 205.000000, Epsilon: 0.100000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-c4ed83bc3a3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CartPole-v1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdqn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDQN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-70-f2e95a03c63c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, games)\u001b[0m\n\u001b[1;32m    167\u001b[0m           \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrewards\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtarget_q\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m           \u001b[0mone_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0mstep_ctr\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mtotal_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-70-f2e95a03c63c>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, x, y, actions)\u001b[0m\n\u001b[1;32m     94\u001b[0m             self.model(x) * actions, axis=1))\n\u001b[1;32m     95\u001b[0m       \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mupdate_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[1;32m    623\u001b[0m             \"ParameterServerStrategy and CentralStorageStrategy\")\n\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m       \u001b[0mapply_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mexperimental_aggregate_gradients\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform_unaggregated_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_prepare\u001b[0;34m(self, var_list)\u001b[0m\n\u001b[1;32m    878\u001b[0m       \u001b[0mapply_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/adam.py\u001b[0m in \u001b[0;36m_prepare_local\u001b[0;34m(self, var_device, var_dtype, apply_state)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0mlocal_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m     \u001b[0mbeta_1_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_hyper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'beta_1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0mbeta_2_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_hyper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'beta_2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0mbeta_1_power\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta_1_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;31m# Make sure we get an input with handle data attached from resource\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;31m# variables. Variables have correct handle data when graph building.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m   \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m   \u001b[0;31m# Propagate handle data for happier shape inference for resource variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1540\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_dense_var_to_tensor\u001b[0;34m(var, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m   1990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1991\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_dense_var_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1992\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_var_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1993\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_dense_var_to_tensor\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1391\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1392\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1393\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1395\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iadd__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munused_other\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mvalue\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_existing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_variable_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcolocate_with\u001b[0;34m(op, ignore_existing)\u001b[0m\n\u001b[1;32m   5313\u001b[0m \u001b[0;31m# only API for those uses to avoid deprecation warning.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5314\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_existing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5315\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_colocate_with_for_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_existing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_existing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_colocate_with_for_gradient\u001b[0;34m(op, gradient_uid, ignore_existing)\u001b[0m\n\u001b[1;32m   5296\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5297\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5298\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mNullContextmanager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5299\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5300\u001b[0m     \u001b[0mdefault_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5K2EQSdhhhsZ",
        "outputId": "3b3a08da-8f01-4786-d57a-4442eaea4edd"
      },
      "source": [
        "env = gym.make(\"CartPole-v1\")\n",
        "def get_dueling(env):\n",
        "  inp = tf.keras.Input(env.observation_space.shape)\n",
        "  x = Dense(24, activation=\"relu\")(inp)\n",
        "  x = Dense(24, activation=\"relu\")(x)\n",
        "  value = Dense(1)(x)\n",
        "  advantage = Dense(env.action_space.n)(x)\n",
        "  out = value + (advantage - tf.reduce_max(advantage))\n",
        "  dueling_model = tf.keras.Model(inputs=inp, outputs=out)\n",
        "  dueling_dqn = DQN(env, model=dueling_model)\n",
        "  return dueling_dqn\n",
        "dueling_dqn = get_dueling(env)\n",
        "dueling_dqn.train(500)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Game: 1, Total Reward: 22.000000, Epsilon: 0.895587\n",
            "Game: 2, Total Reward: 14.000000, Epsilon: 0.834893\n",
            "Game: 3, Total Reward: 14.000000, Epsilon: 0.778313\n",
            "Game: 4, Total Reward: 9.000000, Epsilon: 0.743981\n",
            "Game: 5, Total Reward: 17.000000, Epsilon: 0.683210\n",
            "Game: 6, Total Reward: 14.000000, Epsilon: 0.636909\n",
            "Game: 7, Total Reward: 15.000000, Epsilon: 0.590777\n",
            "Game: 8, Total Reward: 17.000000, Epsilon: 0.542520\n",
            "Game: 9, Total Reward: 9.000000, Epsilon: 0.518589\n",
            "Game: 10, Total Reward: 22.000000, Epsilon: 0.464442\n",
            "Game: 11, Total Reward: 10.000000, Epsilon: 0.441735\n",
            "Game: 12, Total Reward: 12.000000, Epsilon: 0.415948\n",
            "Game: 13, Total Reward: 13.000000, Epsilon: 0.389708\n",
            "Game: 14, Total Reward: 17.000000, Epsilon: 0.357875\n",
            "Game: 15, Total Reward: 25.000000, Epsilon: 0.315725\n",
            "Game: 16, Total Reward: 13.000000, Epsilon: 0.295807\n",
            "Game: 17, Total Reward: 31.000000, Epsilon: 0.253235\n",
            "Game: 18, Total Reward: 10.000000, Epsilon: 0.240855\n",
            "Game: 19, Total Reward: 10.000000, Epsilon: 0.229079\n",
            "Game: 20, Total Reward: 10.000000, Epsilon: 0.217880\n",
            "Game: 21, Total Reward: 21.000000, Epsilon: 0.196111\n",
            "Game: 22, Total Reward: 9.000000, Epsilon: 0.187460\n",
            "Game: 23, Total Reward: 11.000000, Epsilon: 0.177404\n",
            "Game: 24, Total Reward: 11.000000, Epsilon: 0.167887\n",
            "Game: 25, Total Reward: 10.000000, Epsilon: 0.159679\n",
            "Game: 26, Total Reward: 11.000000, Epsilon: 0.151113\n",
            "Game: 27, Total Reward: 12.000000, Epsilon: 0.142291\n",
            "Game: 28, Total Reward: 15.000000, Epsilon: 0.131985\n",
            "Game: 29, Total Reward: 15.000000, Epsilon: 0.122425\n",
            "Game: 30, Total Reward: 104.000000, Epsilon: 0.100000\n",
            "Game: 31, Total Reward: 55.000000, Epsilon: 0.100000\n",
            "Game: 32, Total Reward: 125.000000, Epsilon: 0.100000\n",
            "Game: 33, Total Reward: 106.000000, Epsilon: 0.100000\n",
            "Game: 34, Total Reward: 27.000000, Epsilon: 0.100000\n",
            "Game: 35, Total Reward: 111.000000, Epsilon: 0.100000\n",
            "Game: 36, Total Reward: 48.000000, Epsilon: 0.100000\n",
            "Game: 37, Total Reward: 63.000000, Epsilon: 0.100000\n",
            "Game: 38, Total Reward: 127.000000, Epsilon: 0.100000\n",
            "Game: 39, Total Reward: 113.000000, Epsilon: 0.100000\n",
            "Game: 40, Total Reward: 207.000000, Epsilon: 0.100000\n",
            "Game: 41, Total Reward: 138.000000, Epsilon: 0.100000\n",
            "Game: 42, Total Reward: 121.000000, Epsilon: 0.100000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-132-d99e456f8fbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdueling_dqn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mdueling_dqn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dueling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdueling_dqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-130-814b5c791366>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, games)\u001b[0m\n\u001b[1;32m    165\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0mtarget_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m           \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrewards\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtarget_q\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m           \u001b[0mone_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rRVdQjrbj3F5",
        "outputId": "910f5458-e0ec-46cb-d355-60fa4b804a93"
      },
      "source": [
        "env = gym.make(\"CartPole-v1\")\n",
        "def get_double(env):\n",
        "  double_dqn = DQN(env, double=True, update_freq=50)\n",
        "  return double_dqn\n",
        "double_dqn = get_double(env)\n",
        "double_dqn.train(500)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Game: 1, Total Reward: 29.000000, Epsilon: 0.864708\n",
            "Game: 2, Total Reward: 8.000000, Epsilon: 0.830719\n",
            "Game: 3, Total Reward: 20.000000, Epsilon: 0.751477\n",
            "Game: 4, Total Reward: 54.000000, Epsilon: 0.573274\n",
            "Game: 5, Total Reward: 13.000000, Epsilon: 0.537108\n",
            "Game: 6, Total Reward: 14.000000, Epsilon: 0.500709\n",
            "Game: 7, Total Reward: 11.000000, Epsilon: 0.473848\n",
            "Game: 8, Total Reward: 9.000000, Epsilon: 0.452946\n",
            "Game: 9, Total Reward: 10.000000, Epsilon: 0.430802\n",
            "Game: 10, Total Reward: 10.000000, Epsilon: 0.409740\n",
            "Game: 11, Total Reward: 11.000000, Epsilon: 0.387759\n",
            "Game: 12, Total Reward: 12.000000, Epsilon: 0.365123\n",
            "Game: 13, Total Reward: 13.000000, Epsilon: 0.342089\n",
            "Game: 14, Total Reward: 11.000000, Epsilon: 0.323738\n",
            "Game: 15, Total Reward: 14.000000, Epsilon: 0.301798\n",
            "Game: 16, Total Reward: 10.000000, Epsilon: 0.287043\n",
            "Game: 17, Total Reward: 13.000000, Epsilon: 0.268935\n",
            "Game: 18, Total Reward: 11.000000, Epsilon: 0.254508\n",
            "Game: 19, Total Reward: 9.000000, Epsilon: 0.243281\n",
            "Game: 20, Total Reward: 13.000000, Epsilon: 0.227934\n",
            "Game: 21, Total Reward: 9.000000, Epsilon: 0.217880\n",
            "Game: 22, Total Reward: 11.000000, Epsilon: 0.206191\n",
            "Game: 23, Total Reward: 11.000000, Epsilon: 0.195130\n",
            "Game: 24, Total Reward: 8.000000, Epsilon: 0.187460\n",
            "Game: 25, Total Reward: 10.000000, Epsilon: 0.178295\n",
            "Game: 26, Total Reward: 10.000000, Epsilon: 0.169578\n",
            "Game: 27, Total Reward: 9.000000, Epsilon: 0.162098\n",
            "Game: 28, Total Reward: 9.000000, Epsilon: 0.154948\n",
            "Game: 29, Total Reward: 11.000000, Epsilon: 0.146636\n",
            "Game: 30, Total Reward: 12.000000, Epsilon: 0.138076\n",
            "Game: 31, Total Reward: 11.000000, Epsilon: 0.130668\n",
            "Game: 32, Total Reward: 9.000000, Epsilon: 0.124905\n",
            "Game: 33, Total Reward: 11.000000, Epsilon: 0.118204\n",
            "Game: 34, Total Reward: 10.000000, Epsilon: 0.112425\n",
            "Game: 35, Total Reward: 9.000000, Epsilon: 0.107466\n",
            "Game: 36, Total Reward: 10.000000, Epsilon: 0.102212\n",
            "Game: 37, Total Reward: 12.000000, Epsilon: 0.100000\n",
            "Game: 38, Total Reward: 25.000000, Epsilon: 0.100000\n",
            "Game: 39, Total Reward: 13.000000, Epsilon: 0.100000\n",
            "Game: 40, Total Reward: 11.000000, Epsilon: 0.100000\n",
            "Game: 41, Total Reward: 11.000000, Epsilon: 0.100000\n",
            "Game: 42, Total Reward: 35.000000, Epsilon: 0.100000\n",
            "Game: 43, Total Reward: 97.000000, Epsilon: 0.100000\n",
            "Game: 44, Total Reward: 14.000000, Epsilon: 0.100000\n",
            "Game: 45, Total Reward: 25.000000, Epsilon: 0.100000\n",
            "Game: 46, Total Reward: 53.000000, Epsilon: 0.100000\n",
            "Game: 47, Total Reward: 25.000000, Epsilon: 0.100000\n",
            "Game: 48, Total Reward: 29.000000, Epsilon: 0.100000\n",
            "Game: 49, Total Reward: 16.000000, Epsilon: 0.100000\n",
            "Game: 50, Total Reward: 20.000000, Epsilon: 0.100000\n",
            "Game: 51, Total Reward: 27.000000, Epsilon: 0.100000\n",
            "Game: 52, Total Reward: 50.000000, Epsilon: 0.100000\n",
            "Game: 53, Total Reward: 16.000000, Epsilon: 0.100000\n",
            "Game: 54, Total Reward: 26.000000, Epsilon: 0.100000\n",
            "Game: 55, Total Reward: 38.000000, Epsilon: 0.100000\n",
            "Game: 56, Total Reward: 45.000000, Epsilon: 0.100000\n",
            "Game: 57, Total Reward: 23.000000, Epsilon: 0.100000\n",
            "Game: 58, Total Reward: 30.000000, Epsilon: 0.100000\n",
            "Game: 59, Total Reward: 51.000000, Epsilon: 0.100000\n",
            "Game: 60, Total Reward: 63.000000, Epsilon: 0.100000\n",
            "Game: 61, Total Reward: 38.000000, Epsilon: 0.100000\n",
            "Game: 62, Total Reward: 44.000000, Epsilon: 0.100000\n",
            "Game: 63, Total Reward: 65.000000, Epsilon: 0.100000\n",
            "Game: 64, Total Reward: 53.000000, Epsilon: 0.100000\n",
            "Game: 65, Total Reward: 26.000000, Epsilon: 0.100000\n",
            "Game: 66, Total Reward: 31.000000, Epsilon: 0.100000\n",
            "Game: 67, Total Reward: 47.000000, Epsilon: 0.100000\n",
            "Game: 68, Total Reward: 36.000000, Epsilon: 0.100000\n",
            "Game: 69, Total Reward: 83.000000, Epsilon: 0.100000\n",
            "Game: 70, Total Reward: 38.000000, Epsilon: 0.100000\n",
            "Game: 71, Total Reward: 20.000000, Epsilon: 0.100000\n",
            "Game: 72, Total Reward: 21.000000, Epsilon: 0.100000\n",
            "Game: 73, Total Reward: 34.000000, Epsilon: 0.100000\n",
            "Game: 74, Total Reward: 40.000000, Epsilon: 0.100000\n",
            "Game: 75, Total Reward: 24.000000, Epsilon: 0.100000\n",
            "Game: 76, Total Reward: 111.000000, Epsilon: 0.100000\n",
            "Game: 77, Total Reward: 43.000000, Epsilon: 0.100000\n",
            "Game: 78, Total Reward: 52.000000, Epsilon: 0.100000\n",
            "Game: 79, Total Reward: 30.000000, Epsilon: 0.100000\n",
            "Game: 80, Total Reward: 65.000000, Epsilon: 0.100000\n",
            "Game: 81, Total Reward: 37.000000, Epsilon: 0.100000\n",
            "Game: 82, Total Reward: 179.000000, Epsilon: 0.100000\n",
            "Game: 83, Total Reward: 114.000000, Epsilon: 0.100000\n",
            "Game: 84, Total Reward: 137.000000, Epsilon: 0.100000\n",
            "Game: 85, Total Reward: 100.000000, Epsilon: 0.100000\n",
            "Game: 86, Total Reward: 172.000000, Epsilon: 0.100000\n",
            "Game: 87, Total Reward: 272.000000, Epsilon: 0.100000\n",
            "Game: 88, Total Reward: 125.000000, Epsilon: 0.100000\n",
            "Game: 89, Total Reward: 162.000000, Epsilon: 0.100000\n",
            "Game: 90, Total Reward: 201.000000, Epsilon: 0.100000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-127-c9be645339eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdouble_dqn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdouble_dqn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_double\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdouble_dqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-814b5c791366>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, games)\u001b[0m\n\u001b[1;32m    165\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0mtarget_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m           \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrewards\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtarget_q\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m           \u001b[0mone_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1162\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1164\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1165\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m         \u001b[0;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_mul_dispatch\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1494\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1495\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1496\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmultiply\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    516\u001b[0m   \"\"\"\n\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   6063\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6064\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m-> 6065\u001b[0;31m         _ctx, \"Mul\", name, x, y)\n\u001b[0m\u001b[1;32m   6066\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6067\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bhHaHWT-fbC"
      },
      "source": [
        "class NoisyDense(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, units, input_dim, activation=tf.identity, factorised=False):\n",
        "    super(NoisyDense, self).__init__()\n",
        "    self.factorised = factorised\n",
        "    self.activation = activation\n",
        "    self.units = units\n",
        "    self.input_dim = input_dim\n",
        "    if factorised:\n",
        "      self.mu_initializer = tf.keras.initializers.RandomUniform(-np.sqrt(1 / input_dim), np.sqrt(1 / input_dim))\n",
        "      self.sigma_initializer = tf.keras.initializers.Constant(value=0.5 / np.sqrt(input_dim))\n",
        "    else:\n",
        "      self.mu_initializer = tf.keras.initializers.RandomUniform(-np.sqrt(3 / input_dim), np.sqrt(3 / input_dim))\n",
        "      self.sigma_initializer = tf.keras.initializers.Constant(value=0.2) # 0.017\n",
        "    self.mu_w = tf.Variable(initial_value=self.mu_initializer(shape=(input_dim, units)), trainable=True)\n",
        "    self.mu_b = tf.Variable(initial_value=self.mu_initializer(shape=(units,)), trainable=True)\n",
        "    self.sigma_w = tf.Variable(initial_value=self.sigma_initializer(shape=(input_dim, units)), trainable=True)\n",
        "    self.sigma_b = tf.Variable(initial_value=self.sigma_initializer(shape=(units)), trainable=True)\n",
        "    self.frozen = False\n",
        "  \n",
        "  def process_noise(self, noise):\n",
        "    return tf.multiply(tf.sign(noise), tf.pow(tf.abs(noise), 0.5))\n",
        "\n",
        "  def call(self, inputs):\n",
        "    if self.factorised:\n",
        "      if not self.frozen:\n",
        "        self.epsilon_i = self.process_noise(tf.random.normal(shape=(self.input_dim,)))\n",
        "        self.epsilon_j = self.process_noise(tf.random.normal(shape=(self.units,)))\n",
        "        self.epsilon_ij = tf.tensordot(self.epsilon_i, self.epsilon_j, axes=0)\n",
        "      z = tf.matmul(inputs, self.mu_w + self.sigma_w * self.epsilon_ij) + self.mu_b + self.sigma_b * self.epsilon_j\n",
        "    else:\n",
        "      if not self.frozen:\n",
        "        self.epsilon_mu = self.process_noise(tf.random.normal((self.input_dim, self.units)))\n",
        "        self.epsilon_b = self.process_noise(tf.random.normal((self.units,)))\n",
        "      z = tf.matmul(inputs, self.mu_w + self.sigma_w * self.epsilon_mu) + self.mu_b + self.sigma_b * self.epsilon_b\n",
        "    return self.activation(z)\n",
        "  \n",
        "  def freeze_epsilon(self):\n",
        "    self.frozen = True\n",
        "  \n",
        "  def unfreeze_epsilon(self):\n",
        "    self.frozen = False\n",
        "\n",
        "  def get_epsilon(self):\n",
        "    if self.factorised:\n",
        "      return self.epsilon_i, self.epsilon_j, self.epsilon_ij\n",
        "    else:\n",
        "      return self.epsilon_mu, self.epsilon_b\n",
        "  \n",
        "  def set_epsilon(self, epsilon):\n",
        "    if self.factorised:\n",
        "      self.epsilon_i = epsilon[0]\n",
        "      self.epsilon_j = epsilon[1]\n",
        "      self.epsilon_ij = epsilon[2]\n",
        "    else:\n",
        "      self.epsilon_mu = epsilon[0]\n",
        "      self.epsilon_b = epsilon[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pLksZ23BLlbE",
        "outputId": "f4387c69-69d9-4b8a-8fae-d46bb0c30c98"
      },
      "source": [
        "env = gym.make(\"CartPole-v1\")\n",
        "def get_noisy(env, factorised=False):\n",
        "  inp = tf.keras.Input(env.observation_space.shape)\n",
        "  x = NoisyDense(24, env.observation_space.shape[0], factorised=factorised, activation=tf.keras.activations.relu)(inp)\n",
        "  x = NoisyDense(24, 24, factorised=factorised, activation=tf.keras.activations.relu)(x)\n",
        "  out = NoisyDense(env.action_space.n, 24, factorised=factorised)(x)\n",
        "  noisy_model = tf.keras.Model(inputs=inp, outputs=out)\n",
        "  noisy_dqn = DQN(env, model=noisy_model, noisy=True)\n",
        "  return noisy_dqn\n",
        "noisy_dqn = get_noisy(env, factorised=False)\n",
        "noisy_dqn.train(500)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Game: 1, Total Reward: 18.000000, Epsilon: 1.000000\n",
            "Game: 2, Total Reward: 15.000000, Epsilon: 1.000000\n",
            "Game: 3, Total Reward: 27.000000, Epsilon: 1.000000\n",
            "Game: 4, Total Reward: 26.000000, Epsilon: 1.000000\n",
            "Game: 5, Total Reward: 17.000000, Epsilon: 1.000000\n",
            "Game: 6, Total Reward: 13.000000, Epsilon: 1.000000\n",
            "Game: 7, Total Reward: 18.000000, Epsilon: 1.000000\n",
            "Game: 8, Total Reward: 11.000000, Epsilon: 1.000000\n",
            "Game: 9, Total Reward: 15.000000, Epsilon: 1.000000\n",
            "Game: 10, Total Reward: 10.000000, Epsilon: 1.000000\n",
            "Game: 11, Total Reward: 11.000000, Epsilon: 1.000000\n",
            "Game: 12, Total Reward: 12.000000, Epsilon: 1.000000\n",
            "Game: 13, Total Reward: 12.000000, Epsilon: 1.000000\n",
            "Game: 14, Total Reward: 23.000000, Epsilon: 1.000000\n",
            "Game: 15, Total Reward: 11.000000, Epsilon: 1.000000\n",
            "Game: 16, Total Reward: 11.000000, Epsilon: 1.000000\n",
            "Game: 17, Total Reward: 9.000000, Epsilon: 1.000000\n",
            "Game: 18, Total Reward: 14.000000, Epsilon: 1.000000\n",
            "Game: 19, Total Reward: 11.000000, Epsilon: 1.000000\n",
            "Game: 20, Total Reward: 10.000000, Epsilon: 1.000000\n",
            "Game: 21, Total Reward: 10.000000, Epsilon: 1.000000\n",
            "Game: 22, Total Reward: 11.000000, Epsilon: 1.000000\n",
            "Game: 23, Total Reward: 9.000000, Epsilon: 1.000000\n",
            "Game: 24, Total Reward: 8.000000, Epsilon: 1.000000\n",
            "Game: 25, Total Reward: 11.000000, Epsilon: 1.000000\n",
            "Game: 26, Total Reward: 22.000000, Epsilon: 1.000000\n",
            "Game: 27, Total Reward: 20.000000, Epsilon: 1.000000\n",
            "Game: 28, Total Reward: 16.000000, Epsilon: 1.000000\n",
            "Game: 29, Total Reward: 9.000000, Epsilon: 1.000000\n",
            "Game: 30, Total Reward: 14.000000, Epsilon: 1.000000\n",
            "Game: 31, Total Reward: 9.000000, Epsilon: 1.000000\n",
            "Game: 32, Total Reward: 14.000000, Epsilon: 1.000000\n",
            "Game: 33, Total Reward: 11.000000, Epsilon: 1.000000\n",
            "Game: 34, Total Reward: 14.000000, Epsilon: 1.000000\n",
            "Game: 35, Total Reward: 14.000000, Epsilon: 1.000000\n",
            "Game: 36, Total Reward: 13.000000, Epsilon: 1.000000\n",
            "Game: 37, Total Reward: 10.000000, Epsilon: 1.000000\n",
            "Game: 38, Total Reward: 14.000000, Epsilon: 1.000000\n",
            "Game: 39, Total Reward: 13.000000, Epsilon: 1.000000\n",
            "Game: 40, Total Reward: 12.000000, Epsilon: 1.000000\n",
            "Game: 41, Total Reward: 10.000000, Epsilon: 1.000000\n",
            "Game: 42, Total Reward: 14.000000, Epsilon: 1.000000\n",
            "Game: 43, Total Reward: 16.000000, Epsilon: 1.000000\n",
            "Game: 44, Total Reward: 29.000000, Epsilon: 1.000000\n",
            "Game: 45, Total Reward: 20.000000, Epsilon: 1.000000\n",
            "Game: 46, Total Reward: 17.000000, Epsilon: 1.000000\n",
            "Game: 47, Total Reward: 30.000000, Epsilon: 1.000000\n",
            "Game: 48, Total Reward: 76.000000, Epsilon: 1.000000\n",
            "Game: 49, Total Reward: 23.000000, Epsilon: 1.000000\n",
            "Game: 50, Total Reward: 20.000000, Epsilon: 1.000000\n",
            "Game: 51, Total Reward: 49.000000, Epsilon: 1.000000\n",
            "Game: 52, Total Reward: 18.000000, Epsilon: 1.000000\n",
            "Game: 53, Total Reward: 14.000000, Epsilon: 1.000000\n",
            "Game: 54, Total Reward: 10.000000, Epsilon: 1.000000\n",
            "Game: 55, Total Reward: 15.000000, Epsilon: 1.000000\n",
            "Game: 56, Total Reward: 9.000000, Epsilon: 1.000000\n",
            "Game: 57, Total Reward: 10.000000, Epsilon: 1.000000\n",
            "Game: 58, Total Reward: 9.000000, Epsilon: 1.000000\n",
            "Game: 59, Total Reward: 8.000000, Epsilon: 1.000000\n",
            "Game: 60, Total Reward: 9.000000, Epsilon: 1.000000\n",
            "Game: 61, Total Reward: 13.000000, Epsilon: 1.000000\n",
            "Game: 62, Total Reward: 10.000000, Epsilon: 1.000000\n",
            "Game: 63, Total Reward: 9.000000, Epsilon: 1.000000\n",
            "Game: 64, Total Reward: 11.000000, Epsilon: 1.000000\n",
            "Game: 65, Total Reward: 42.000000, Epsilon: 1.000000\n",
            "Game: 66, Total Reward: 22.000000, Epsilon: 1.000000\n",
            "Game: 67, Total Reward: 13.000000, Epsilon: 1.000000\n",
            "Game: 68, Total Reward: 11.000000, Epsilon: 1.000000\n",
            "Game: 69, Total Reward: 24.000000, Epsilon: 1.000000\n",
            "Game: 70, Total Reward: 15.000000, Epsilon: 1.000000\n",
            "Game: 71, Total Reward: 12.000000, Epsilon: 1.000000\n",
            "Game: 72, Total Reward: 16.000000, Epsilon: 1.000000\n",
            "Game: 73, Total Reward: 12.000000, Epsilon: 1.000000\n",
            "Game: 74, Total Reward: 15.000000, Epsilon: 1.000000\n",
            "Game: 75, Total Reward: 73.000000, Epsilon: 1.000000\n",
            "Game: 76, Total Reward: 27.000000, Epsilon: 1.000000\n",
            "Game: 77, Total Reward: 97.000000, Epsilon: 1.000000\n",
            "Game: 78, Total Reward: 112.000000, Epsilon: 1.000000\n",
            "Game: 79, Total Reward: 22.000000, Epsilon: 1.000000\n",
            "Game: 80, Total Reward: 33.000000, Epsilon: 1.000000\n",
            "Game: 81, Total Reward: 45.000000, Epsilon: 1.000000\n",
            "Game: 82, Total Reward: 45.000000, Epsilon: 1.000000\n",
            "Game: 83, Total Reward: 20.000000, Epsilon: 1.000000\n",
            "Game: 84, Total Reward: 74.000000, Epsilon: 1.000000\n",
            "Game: 85, Total Reward: 44.000000, Epsilon: 1.000000\n",
            "Game: 86, Total Reward: 40.000000, Epsilon: 1.000000\n",
            "Game: 87, Total Reward: 76.000000, Epsilon: 1.000000\n",
            "Game: 88, Total Reward: 43.000000, Epsilon: 1.000000\n",
            "Game: 89, Total Reward: 62.000000, Epsilon: 1.000000\n",
            "Game: 90, Total Reward: 39.000000, Epsilon: 1.000000\n",
            "Game: 91, Total Reward: 30.000000, Epsilon: 1.000000\n",
            "Game: 92, Total Reward: 87.000000, Epsilon: 1.000000\n",
            "Game: 93, Total Reward: 106.000000, Epsilon: 1.000000\n",
            "Game: 94, Total Reward: 72.000000, Epsilon: 1.000000\n",
            "Game: 95, Total Reward: 68.000000, Epsilon: 1.000000\n",
            "Game: 96, Total Reward: 67.000000, Epsilon: 1.000000\n",
            "Game: 97, Total Reward: 38.000000, Epsilon: 1.000000\n",
            "Game: 98, Total Reward: 112.000000, Epsilon: 1.000000\n",
            "Game: 99, Total Reward: 125.000000, Epsilon: 1.000000\n",
            "Game: 100, Total Reward: 110.000000, Epsilon: 1.000000\n",
            "Game: 101, Total Reward: 70.000000, Epsilon: 1.000000\n",
            "Game: 102, Total Reward: 316.000000, Epsilon: 1.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-144-9d11190602af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnoisy_dqn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mnoisy_dqn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_noisy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactorised\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mnoisy_dqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-130-814b5c791366>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, games)\u001b[0m\n\u001b[1;32m    167\u001b[0m           \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrewards\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtarget_q\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m           \u001b[0mone_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0mstep_ctr\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mtotal_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-130-814b5c791366>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, x, y, actions)\u001b[0m\n\u001b[1;32m     94\u001b[0m             self.model(x) * actions, axis=1))\n\u001b[1;32m     95\u001b[0m       \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mupdate_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[1;32m    633\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m           kwargs={\n\u001b[0;32m--> 635\u001b[0;31m               \u001b[0;34m\"name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m           })\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mmerge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m     merge_fn = autograph.tf_convert(\n\u001b[1;32m   2940\u001b[0m         merge_fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 2941\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2943\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_merge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2946\u001b[0m         distribution_strategy_context._CrossReplicaThreadMode(self._strategy))  # pylint: disable=protected-access\n\u001b[1;32m   2947\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2948\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2949\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2950\u001b[0m       \u001b[0m_pop_per_thread_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    570\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_distributed_apply\u001b[0;34m(self, distribution, grads_and_vars, name, apply_state)\u001b[0m\n\u001b[1;32m    681\u001b[0m                               \"update_\" + var.op.name, skip_on_eager=True):\n\u001b[1;32m    682\u001b[0m             update_ops.extend(distribution.extended.update(\n\u001b[0;32m--> 683\u001b[0;31m                 var, apply_grad_to_update_var, args=(grad,), group=False))\n\u001b[0m\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m       any_symbolic = any(isinstance(i, ops.Operation) or\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, *ex_info)\u001b[0m\n\u001b[1;32m   1794\u001b[0m     \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ctx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1795\u001b[0m     \u001b[0mold_device_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_device_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_device_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1796\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_spec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnew_device_spec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1797\u001b[0m       raise RuntimeError(\n\u001b[1;32m   1798\u001b[0m           \"Exiting device scope without proper scope nesting\")\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mdevice_spec\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    843\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mdevice_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m     \u001b[0;34m\"\"\"Returns the device spec for the current thread.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_set_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hXd9M_O2Ls8j",
        "outputId": "0f197521-a686-4f26-ed87-4549a07c1a99"
      },
      "source": [
        "N_ATOMS = 5\n",
        "V_MIN = 0\n",
        "V_MAX = 4\n",
        "env = gym.make(\"CartPole-v1\")\n",
        "def get_distributional(env, n_atoms, v_min, v_max):\n",
        "  z = np.array([V_MIN + i * (V_MAX - V_MIN) / (N_ATOMS - 1) for i in range(N_ATOMS)])\n",
        "  inp = tf.keras.Input(env.observation_space.shape)\n",
        "  x = Dense(12, activation=\"relu\")(inp)\n",
        "  x = Dense(12, activation=\"relu\")(x)\n",
        "  out = [Dense(N_ATOMS, activation=\"softmax\")(x) for _ in range(env.action_space.n)]\n",
        "  distributional_model = tf.keras.Model(inputs=inp, outputs=out)\n",
        "  distributional_dqn = DQN(env, loss=tf.keras.losses.CategoricalCrossentropy(), model=distributional_model, distributional=True, v_max=V_MAX, v_min=V_MIN, z=z, n_atoms=N_ATOMS)\n",
        "  return distributional_dqn\n",
        "distributional_dqn = get_distributional(env, N_ATOMS, V_MIN, V_MAX)\n",
        "distributional_dqn.train(500)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Game: 1, Total Reward: 25.000000, Epsilon: 0.882220\n",
            "Game: 2, Total Reward: 53.000000, Epsilon: 0.676395\n",
            "Game: 3, Total Reward: 23.000000, Epsilon: 0.602742\n",
            "Game: 4, Total Reward: 15.000000, Epsilon: 0.559084\n",
            "Game: 5, Total Reward: 14.000000, Epsilon: 0.521195\n",
            "Game: 6, Total Reward: 16.000000, Epsilon: 0.481027\n",
            "Game: 7, Total Reward: 12.000000, Epsilon: 0.452946\n",
            "Game: 8, Total Reward: 19.000000, Epsilon: 0.411799\n",
            "Game: 9, Total Reward: 11.000000, Epsilon: 0.389708\n",
            "Game: 10, Total Reward: 12.000000, Epsilon: 0.366958\n",
            "Game: 11, Total Reward: 11.000000, Epsilon: 0.347272\n",
            "Game: 12, Total Reward: 15.000000, Epsilon: 0.322119\n",
            "Game: 13, Total Reward: 31.000000, Epsilon: 0.275760\n",
            "Game: 14, Total Reward: 10.000000, Epsilon: 0.262278\n",
            "Game: 15, Total Reward: 11.000000, Epsilon: 0.248208\n",
            "Game: 16, Total Reward: 11.000000, Epsilon: 0.234893\n",
            "Game: 17, Total Reward: 8.000000, Epsilon: 0.225660\n",
            "Game: 18, Total Reward: 16.000000, Epsilon: 0.208269\n",
            "Game: 19, Total Reward: 36.000000, Epsilon: 0.173882\n",
            "Game: 20, Total Reward: 147.000000, Epsilon: 0.100000\n",
            "Game: 21, Total Reward: 35.000000, Epsilon: 0.100000\n",
            "Game: 22, Total Reward: 54.000000, Epsilon: 0.100000\n",
            "Game: 23, Total Reward: 52.000000, Epsilon: 0.100000\n",
            "Game: 24, Total Reward: 56.000000, Epsilon: 0.100000\n",
            "Game: 25, Total Reward: 48.000000, Epsilon: 0.100000\n",
            "Game: 26, Total Reward: 47.000000, Epsilon: 0.100000\n",
            "Game: 27, Total Reward: 43.000000, Epsilon: 0.100000\n",
            "Game: 28, Total Reward: 55.000000, Epsilon: 0.100000\n",
            "Game: 29, Total Reward: 65.000000, Epsilon: 0.100000\n",
            "Game: 30, Total Reward: 51.000000, Epsilon: 0.100000\n",
            "Game: 31, Total Reward: 33.000000, Epsilon: 0.100000\n",
            "Game: 32, Total Reward: 47.000000, Epsilon: 0.100000\n",
            "Game: 33, Total Reward: 33.000000, Epsilon: 0.100000\n",
            "Game: 34, Total Reward: 38.000000, Epsilon: 0.100000\n",
            "Game: 35, Total Reward: 50.000000, Epsilon: 0.100000\n",
            "Game: 36, Total Reward: 153.000000, Epsilon: 0.100000\n",
            "Game: 37, Total Reward: 32.000000, Epsilon: 0.100000\n",
            "Game: 38, Total Reward: 37.000000, Epsilon: 0.100000\n",
            "Game: 39, Total Reward: 89.000000, Epsilon: 0.100000\n",
            "Game: 40, Total Reward: 15.000000, Epsilon: 0.100000\n",
            "Game: 41, Total Reward: 11.000000, Epsilon: 0.100000\n",
            "Game: 42, Total Reward: 11.000000, Epsilon: 0.100000\n",
            "Game: 43, Total Reward: 9.000000, Epsilon: 0.100000\n",
            "Game: 44, Total Reward: 12.000000, Epsilon: 0.100000\n",
            "Game: 45, Total Reward: 13.000000, Epsilon: 0.100000\n",
            "Game: 46, Total Reward: 13.000000, Epsilon: 0.100000\n",
            "Game: 47, Total Reward: 9.000000, Epsilon: 0.100000\n",
            "Game: 48, Total Reward: 10.000000, Epsilon: 0.100000\n",
            "Game: 49, Total Reward: 10.000000, Epsilon: 0.100000\n",
            "Game: 50, Total Reward: 11.000000, Epsilon: 0.100000\n",
            "Game: 51, Total Reward: 10.000000, Epsilon: 0.100000\n",
            "Game: 52, Total Reward: 9.000000, Epsilon: 0.100000\n",
            "Game: 53, Total Reward: 12.000000, Epsilon: 0.100000\n",
            "Game: 54, Total Reward: 8.000000, Epsilon: 0.100000\n",
            "Game: 55, Total Reward: 8.000000, Epsilon: 0.100000\n",
            "Game: 56, Total Reward: 10.000000, Epsilon: 0.100000\n",
            "Game: 57, Total Reward: 11.000000, Epsilon: 0.100000\n",
            "Game: 58, Total Reward: 9.000000, Epsilon: 0.100000\n",
            "Game: 59, Total Reward: 11.000000, Epsilon: 0.100000\n",
            "Game: 60, Total Reward: 12.000000, Epsilon: 0.100000\n",
            "Game: 61, Total Reward: 22.000000, Epsilon: 0.100000\n",
            "Game: 62, Total Reward: 63.000000, Epsilon: 0.100000\n",
            "Game: 63, Total Reward: 18.000000, Epsilon: 0.100000\n",
            "Game: 64, Total Reward: 79.000000, Epsilon: 0.100000\n",
            "Game: 65, Total Reward: 70.000000, Epsilon: 0.100000\n",
            "Game: 66, Total Reward: 81.000000, Epsilon: 0.100000\n",
            "Game: 67, Total Reward: 43.000000, Epsilon: 0.100000\n",
            "Game: 68, Total Reward: 70.000000, Epsilon: 0.100000\n",
            "Game: 69, Total Reward: 52.000000, Epsilon: 0.100000\n",
            "Game: 70, Total Reward: 49.000000, Epsilon: 0.100000\n",
            "Game: 71, Total Reward: 91.000000, Epsilon: 0.100000\n",
            "Game: 72, Total Reward: 89.000000, Epsilon: 0.100000\n",
            "Game: 73, Total Reward: 46.000000, Epsilon: 0.100000\n",
            "Game: 74, Total Reward: 21.000000, Epsilon: 0.100000\n",
            "Game: 75, Total Reward: 36.000000, Epsilon: 0.100000\n",
            "Game: 76, Total Reward: 120.000000, Epsilon: 0.100000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-152-19ef46f3a78c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdistributional_dqn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mdistributional_dqn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_distributional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_ATOMS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV_MIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV_MAX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mdistributional_dqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-130-814b5c791366>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, games)\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0mbj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTz\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_min\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                 \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                 \u001b[0mm_prob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext_actions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m                 \u001b[0mm_prob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext_actions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbj\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m   1045\u001b[0m         \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0mvar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m   6653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6654\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_arg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_arg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback_arg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6655\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exit_fns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_arg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_arg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback_arg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6656\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# False values do not suppress exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_restore_name_scope\u001b[0;34m(*_)\u001b[0m\n\u001b[1;32m   6643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6644\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0m_restore_name_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6645\u001b[0;31m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6647\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exit_fns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_restore_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mscope_name\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m    830\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m   \u001b[0;34m@\u001b[0m\u001b[0mscope_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mscope_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m     \u001b[0;34m\"\"\"Sets scope name for the current thread.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iu8uG4zFhm6C"
      },
      "source": [
        "class PERBuffer: #TODO: keep a numpy array of the probs, keep track of the minimum\n",
        "\n",
        "  def __init__(self, max_len=1_000_000):\n",
        "    self.samples = deque()\n",
        "    self.probs = deque()\n",
        "    self.max = 1\n",
        "    self.sum = 0\n",
        "    self.max_len = max_len\n",
        "  \n",
        "  def add(self, s, a, r, s1, d):\n",
        "    self.samples.append((s, a, r, s1, d))\n",
        "    self.probs.append(self.max)\n",
        "    self.sum += self.max\n",
        "    if len(self.samples) > self.max_len:\n",
        "      self.sum -= self.probs.popleft()\n",
        "      self.samples.popleft()\n",
        "  \n",
        "  def set(self, idx, val):\n",
        "    if val > self.max:\n",
        "      self.max = val\n",
        "    self.sum += val - self.probs[idx]\n",
        "    reset_max = False\n",
        "    if self.probs[idx] == self.max:\n",
        "      reset_max = True\n",
        "    self.probs[idx] = val\n",
        "    if reset_max:\n",
        "      self.max = max(self.probs)\n",
        "  \n",
        "  def sample(self, size):\n",
        "    if size > len(self.samples):\n",
        "      return None\n",
        "    else:\n",
        "      p = np.array(self.probs, dtype=np.float32)\n",
        "      p /= p.sum()\n",
        "      p /= p.sum()\n",
        "      indices = np.random.choice(np.arange(len(self.samples)), size=size, replace=False, p=p)\n",
        "      samples = [self.samples[i] for i in indices]\n",
        "      probs = np.array([self.probs[i] for i in indices])\n",
        "      div_probs = probs / self.sum\n",
        "      return samples, indices, div_probs"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhzeH6py3_bz"
      },
      "source": [
        "class PERDQN:\n",
        "\n",
        "  def __init__(self, env, opt=None, loss=None, epsilon_init=1, \n",
        "               epsilon_decay=0.995, epsilon_min=0.1, epsilon_op=\"multiply\", batch_size=32,\n",
        "               buffer_length=1_000_000, gamma=0.95, model=None, alpha=1, beta=0.5, replay_freq=1, w=True):\n",
        "    self.env = env\n",
        "    self.obs_dim = env.observation_space.shape[0]\n",
        "    self.act_dim = env.action_space.n\n",
        "    self.opt = self.set_opt(opt)\n",
        "    self.loss = self.set_loss(loss)\n",
        "    self.epsilon_init = epsilon_init\n",
        "    self.epsilon = epsilon_init\n",
        "    self.epsilon_decay = epsilon_decay\n",
        "    self.epsilon_min = epsilon_min\n",
        "    self.epsilon_op = epsilon_op\n",
        "    self.batch_size = batch_size\n",
        "    self.gamma = gamma\n",
        "    self.buffer = PERBuffer(max_len=buffer_length)\n",
        "    self.model = self.set_model(model)\n",
        "    self.alpha = alpha\n",
        "    self.beta = beta\n",
        "\n",
        "    self.replay_freq = replay_freq\n",
        "    self.w = w\n",
        "  \n",
        "  def set_opt(self, opt):\n",
        "    if opt is None:\n",
        "      return tf.keras.optimizers.Adam()\n",
        "    else:\n",
        "      return opt\n",
        "  \n",
        "  def set_loss(self, loss):\n",
        "    if loss is None:\n",
        "      return tf.keras.losses.MSE\n",
        "    else:\n",
        "      return loss\n",
        "  \n",
        "  def set_model(self, model):\n",
        "    if model is None:\n",
        "      inp = tf.keras.Input(self.obs_dim)\n",
        "      x = Dense(24, activation=\"relu\")(inp)\n",
        "      x = Dense(24, activation=\"relu\")(x)\n",
        "      out = Dense(self.act_dim)(x)\n",
        "      return tf.keras.Model(inputs=inp, outputs=out)\n",
        "    else:\n",
        "      return model\n",
        "  \n",
        "  def decay_epsilon(self):\n",
        "    if self.epsilon_op == \"multiply\":\n",
        "      self.epsilon *= self.epsilon_decay\n",
        "    else:\n",
        "      self.epsilon -= self.epsilon_decay\n",
        "    self.epsilon = max(self.epsilon, self.epsilon_min)\n",
        "  \n",
        "  def act(self, x):\n",
        "    if np.random.random() < self.epsilon:\n",
        "      self.decay_epsilon()\n",
        "      return self.env.action_space.sample()\n",
        "    else:\n",
        "      self.decay_epsilon()\n",
        "      pred = self.model(x[np.newaxis, :])\n",
        "      return np.argmax(pred)\n",
        "  \n",
        "  def train(self, episodes): # maybe increase learning rate to balance out the weight\n",
        "    reward_list = []\n",
        "    total_steps = 0\n",
        "    for episode in range(episodes):\n",
        "      s = self.env.reset()\n",
        "      d = False\n",
        "      s1 = None\n",
        "      game_reward = 0\n",
        "      while not d:\n",
        "        a = self.act(s)\n",
        "        s1, r, d, _ = self.env.step(a)\n",
        "        game_reward += r\n",
        "        if total_steps % self.replay_freq == 0 and len(self.buffer.samples) >= self.batch_size:\n",
        "          delta = []\n",
        "          for j in range(self.batch_size):\n",
        "            sample, index, prob = self.buffer.sample(1)\n",
        "            sample = sample[0]\n",
        "            index = index[0]\n",
        "            prob = prob[0]\n",
        "            if self.w:\n",
        "              w = ((len(self.buffer.samples) * prob) ** -self.beta) / ((len(self.buffer.samples) * min(self.buffer.probs) / self.buffer.sum) ** -self.beta)\n",
        "            else:\n",
        "              w = 1\n",
        "            action_one_hot = np.zeros((1, self.act_dim))\n",
        "            action_one_hot[0, sample[1]] = 1\n",
        "            action_one_hot = tf.constant(action_one_hot, dtype=tf.float32)\n",
        "            with tf.GradientTape() as tape:\n",
        "              pred = self.model(sample[0][np.newaxis, :])\n",
        "              pred *= action_one_hot\n",
        "              if sample[4]:\n",
        "                loss = self.loss(tf.constant(sample[2]), tf.reduce_sum(pred, axis=1))\n",
        "              else:\n",
        "                loss = self.loss(tf.constant(sample[2] + self.gamma * np.amax(np.squeeze(self.model(sample[3][np.newaxis, :])))), tf.reduce_sum(pred, axis=1))\n",
        "            grad = tape.gradient(loss, self.model.trainable_weights)\n",
        "            self.buffer.set(index, loss ** self.alpha)\n",
        "            if delta == []:\n",
        "              for i in grad:\n",
        "                delta.append(w * i)\n",
        "            else:\n",
        "              for i, v in enumerate(grad):\n",
        "                delta[i] += w * grad[i]\n",
        "          self.opt.apply_gradients(zip(delta, self.model.trainable_weights))\n",
        "        total_steps += 1\n",
        "        self.buffer.add(s, a, r, s1, d)\n",
        "        s = s1\n",
        "        s1 = None\n",
        "      reward_list.append(game_reward)\n",
        "      print(\"Episode: %d, Reward: %f, Epsilon: %f\" % (episode + 1, game_reward, self.epsilon))\n",
        "    return reward_list"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pqfmve7dJjN"
      },
      "source": [
        "dqn = PERDQN(gym.make(\"CartPole-v1\"))\n",
        "dqn.train(200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_8wakKQn35m"
      },
      "source": [
        "class NStepDQN:\n",
        "\n",
        "  def __init__(self, env, opt=None, loss=None, epsilon_init=1, \n",
        "               epsilon_decay=0.995, epsilon_min=0.1, epsilon_op=\"multiply\", batch_size=32,\n",
        "               buffer_length=1_000_000, gamma=0.95, model=None, n_step=5):\n",
        "    self.env = env\n",
        "    self.obs_dim = env.observation_space.shape[0]\n",
        "    self.act_dim = env.action_space.n\n",
        "    self.opt = self.set_opt(opt)\n",
        "    self.loss = self.set_loss(loss)\n",
        "    self.epsilon_init = epsilon_init\n",
        "    self.epsilon = epsilon_init\n",
        "    self.epsilon_decay = epsilon_decay\n",
        "    self.epsilon_min = epsilon_min\n",
        "    self.epsilon_op = epsilon_op\n",
        "    self.batch_size = batch_size\n",
        "    self.gamma = gamma\n",
        "    self.buffer = ReplayBuffer(max_size=buffer_length)\n",
        "    self.model = self.set_model(model)\n",
        "    self.n_step = n_step\n",
        "  \n",
        "  def set_opt(self, opt):\n",
        "    if opt is None:\n",
        "      return tf.keras.optimizers.Adam()\n",
        "    else:\n",
        "      return opt\n",
        "  \n",
        "  def set_loss(self, loss):\n",
        "    if loss is None:\n",
        "      return tf.keras.losses.MSE\n",
        "    else:\n",
        "      return loss\n",
        "  \n",
        "  def set_model(self, model):\n",
        "    if model is None:\n",
        "      inp = tf.keras.Input(self.obs_dim)\n",
        "      x = Dense(24, activation=\"relu\")(inp)\n",
        "      x = Dense(24, activation=\"relu\")(x)\n",
        "      out = Dense(self.act_dim)(x)\n",
        "      return tf.keras.Model(inputs=inp, outputs=out)\n",
        "    else:\n",
        "      return model\n",
        "  \n",
        "  def decay_epsilon(self):\n",
        "    if self.epsilon_op == \"multiply\":\n",
        "      self.epsilon *= self.epsilon_decay\n",
        "    else:\n",
        "      self.epsilon -= self.epsilon_decay\n",
        "    self.epsilon = max(self.epsilon, self.epsilon_min)\n",
        "  \n",
        "  def act(self, x):\n",
        "    if np.random.random() < self.epsilon:\n",
        "      self.decay_epsilon()\n",
        "      return self.env.action_space.sample()\n",
        "    else:\n",
        "      self.decay_epsilon()\n",
        "      pred = self.model(x)\n",
        "      return np.argmax(pred)\n",
        "  \n",
        "  def train(self, episodes):\n",
        "    reward_list = []\n",
        "    for episode in range(episodes):\n",
        "      states = deque()\n",
        "      rewards = deque()\n",
        "      actions = deque()\n",
        "      states.append(self.env.reset())\n",
        "      rewards.append(0)\n",
        "      actions.append(0)\n",
        "      d = False\n",
        "      game_reward = 0\n",
        "      while not d:\n",
        "        a = self.act(states[-1][np.newaxis, :])\n",
        "        s1, r, d, _ = self.env.step(a)\n",
        "        game_reward += r\n",
        "        states.append(s1)\n",
        "        rewards.append(r)\n",
        "        actions.append(a)\n",
        "        if len(states) > self.n_step:\n",
        "          states.popleft()\n",
        "          rewards.popleft()\n",
        "          actions.popleft()\n",
        "        if len(states) == self.n_step:\n",
        "          S = states[0]\n",
        "          S1 = states[-1]\n",
        "          R = 0\n",
        "          for i in range(self.n_step):\n",
        "            R += rewards[i] * (self.gamma ** i)\n",
        "          A = actions[0]\n",
        "          D = d\n",
        "          self.buffer.add(S, A, R, S1, D)\n",
        "        if len(self.buffer.buffer) >= self.batch_size:\n",
        "          exp = self.buffer.sample(self.batch_size)\n",
        "          states_ = np.array([i[0] for i in exp])\n",
        "          actions_ = np.array([i[1] for i in exp])\n",
        "          rewards_ = np.array([i[2] for i in exp])\n",
        "          nexts_ = np.array([i[3] for i in exp])\n",
        "          dones_ = np.array([i[4] for i in exp])\n",
        "          target_q = self.model(nexts_)\n",
        "          one_hot = tf.one_hot(actions_, self.act_dim)\n",
        "          targets = rewards_ + tf.math.reduce_max(tf.transpose(tf.transpose((self.gamma ** self.n_step) * target_q) * (1 - dones_)), axis=1)\n",
        "          with tf.GradientTape() as tape:\n",
        "            loss = self.loss(targets, tf.reduce_sum(self.model(states_) * one_hot, axis=1))\n",
        "          grad = tape.gradient(loss, self.model.trainable_weights)\n",
        "          self.opt.apply_gradients(zip(grad, self.model.trainable_weights))\n",
        "      reward_list.append(game_reward)\n",
        "      print(\"Game: %d, Reward: %f, Epsilon: %f\" % (episode + 1, game_reward, self.epsilon))\n",
        "    return reward_list"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQesEHCldD89"
      },
      "source": [
        "dqn = NStepDQN(gym.make(\"CartPole-v1\"), epsilon_decay=0.999)\n",
        "dqn.train(200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EW9sSx7BdjVf",
        "outputId": "0f237405-7ab1-4232-82f0-25f827db59d7"
      },
      "source": [
        "%matplotlib inline\n",
        "def train_and_plot(class_object, env, episodes, runs):\n",
        "  losses = []\n",
        "  for _ in range(runs):\n",
        "    losses.append(class_object(env).train(episodes))\n",
        "  for i in losses:\n",
        "    plt.plot(range(1, episodes + 1), i)\n",
        "  plt.show()\n",
        "\n",
        "train_and_plot(DQN, gym.make(\"CartPole-v1\"), 200, 5)\n",
        "################################################\n",
        "# NONE OF THE CODE AFTER THIS CELL IS FUNCTIONAL #\n",
        "################################################"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Game: 1, Total Reward: 22.000000, Epsilon: 0.895587\n",
            "Game: 2, Total Reward: 21.000000, Epsilon: 0.806107\n",
            "Game: 3, Total Reward: 14.000000, Epsilon: 0.751477\n",
            "Game: 4, Total Reward: 12.000000, Epsilon: 0.707608\n",
            "Game: 5, Total Reward: 8.000000, Epsilon: 0.679794\n",
            "Game: 6, Total Reward: 10.000000, Epsilon: 0.646559\n",
            "Game: 7, Total Reward: 9.000000, Epsilon: 0.618039\n",
            "Game: 8, Total Reward: 16.000000, Epsilon: 0.570407\n",
            "Game: 9, Total Reward: 14.000000, Epsilon: 0.531751\n",
            "Game: 10, Total Reward: 19.000000, Epsilon: 0.483445\n",
            "Game: 11, Total Reward: 13.000000, Epsilon: 0.452946\n",
            "Game: 12, Total Reward: 15.000000, Epsilon: 0.420139\n",
            "Game: 13, Total Reward: 12.000000, Epsilon: 0.395612\n",
            "Game: 14, Total Reward: 11.000000, Epsilon: 0.374390\n",
            "Game: 15, Total Reward: 11.000000, Epsilon: 0.354305\n",
            "Game: 16, Total Reward: 9.000000, Epsilon: 0.338677\n",
            "Game: 17, Total Reward: 9.000000, Epsilon: 0.323738\n",
            "Game: 18, Total Reward: 12.000000, Epsilon: 0.304839\n",
            "Game: 19, Total Reward: 16.000000, Epsilon: 0.281345\n",
            "Game: 20, Total Reward: 13.000000, Epsilon: 0.263596\n",
            "Game: 21, Total Reward: 8.000000, Epsilon: 0.253235\n",
            "Game: 22, Total Reward: 11.000000, Epsilon: 0.239650\n",
            "Game: 23, Total Reward: 9.000000, Epsilon: 0.229079\n",
            "Game: 24, Total Reward: 10.000000, Epsilon: 0.217880\n",
            "Game: 25, Total Reward: 13.000000, Epsilon: 0.204135\n",
            "Game: 26, Total Reward: 12.000000, Epsilon: 0.192218\n",
            "Game: 27, Total Reward: 10.000000, Epsilon: 0.182820\n",
            "Game: 28, Total Reward: 12.000000, Epsilon: 0.172148\n",
            "Game: 29, Total Reward: 13.000000, Epsilon: 0.161288\n",
            "Game: 30, Total Reward: 14.000000, Epsilon: 0.150357\n",
            "Game: 31, Total Reward: 11.000000, Epsilon: 0.142291\n",
            "Game: 32, Total Reward: 12.000000, Epsilon: 0.133985\n",
            "Game: 33, Total Reward: 15.000000, Epsilon: 0.124280\n",
            "Game: 34, Total Reward: 11.000000, Epsilon: 0.117613\n",
            "Game: 35, Total Reward: 11.000000, Epsilon: 0.111304\n",
            "Game: 36, Total Reward: 11.000000, Epsilon: 0.105333\n",
            "Game: 37, Total Reward: 11.000000, Epsilon: 0.100000\n",
            "Game: 38, Total Reward: 14.000000, Epsilon: 0.100000\n",
            "Game: 39, Total Reward: 12.000000, Epsilon: 0.100000\n",
            "Game: 40, Total Reward: 18.000000, Epsilon: 0.100000\n",
            "Game: 41, Total Reward: 20.000000, Epsilon: 0.100000\n",
            "Game: 42, Total Reward: 23.000000, Epsilon: 0.100000\n",
            "Game: 43, Total Reward: 17.000000, Epsilon: 0.100000\n",
            "Game: 44, Total Reward: 57.000000, Epsilon: 0.100000\n",
            "Game: 45, Total Reward: 27.000000, Epsilon: 0.100000\n",
            "Game: 46, Total Reward: 29.000000, Epsilon: 0.100000\n",
            "Game: 47, Total Reward: 15.000000, Epsilon: 0.100000\n",
            "Game: 48, Total Reward: 10.000000, Epsilon: 0.100000\n",
            "Game: 49, Total Reward: 10.000000, Epsilon: 0.100000\n",
            "Game: 50, Total Reward: 9.000000, Epsilon: 0.100000\n",
            "Game: 51, Total Reward: 9.000000, Epsilon: 0.100000\n",
            "Game: 52, Total Reward: 9.000000, Epsilon: 0.100000\n",
            "Game: 53, Total Reward: 10.000000, Epsilon: 0.100000\n",
            "Game: 54, Total Reward: 10.000000, Epsilon: 0.100000\n",
            "Game: 55, Total Reward: 17.000000, Epsilon: 0.100000\n",
            "Game: 56, Total Reward: 38.000000, Epsilon: 0.100000\n",
            "Game: 57, Total Reward: 15.000000, Epsilon: 0.100000\n",
            "Game: 58, Total Reward: 19.000000, Epsilon: 0.100000\n",
            "Game: 59, Total Reward: 13.000000, Epsilon: 0.100000\n",
            "Game: 60, Total Reward: 25.000000, Epsilon: 0.100000\n",
            "Game: 61, Total Reward: 18.000000, Epsilon: 0.100000\n",
            "Game: 62, Total Reward: 12.000000, Epsilon: 0.100000\n",
            "Game: 63, Total Reward: 20.000000, Epsilon: 0.100000\n",
            "Game: 64, Total Reward: 37.000000, Epsilon: 0.100000\n",
            "Game: 65, Total Reward: 24.000000, Epsilon: 0.100000\n",
            "Game: 66, Total Reward: 25.000000, Epsilon: 0.100000\n",
            "Game: 67, Total Reward: 14.000000, Epsilon: 0.100000\n",
            "Game: 68, Total Reward: 17.000000, Epsilon: 0.100000\n",
            "Game: 69, Total Reward: 27.000000, Epsilon: 0.100000\n",
            "Game: 70, Total Reward: 19.000000, Epsilon: 0.100000\n",
            "Game: 71, Total Reward: 14.000000, Epsilon: 0.100000\n",
            "Game: 72, Total Reward: 27.000000, Epsilon: 0.100000\n",
            "Game: 73, Total Reward: 63.000000, Epsilon: 0.100000\n",
            "Game: 74, Total Reward: 15.000000, Epsilon: 0.100000\n",
            "Game: 75, Total Reward: 30.000000, Epsilon: 0.100000\n",
            "Game: 76, Total Reward: 24.000000, Epsilon: 0.100000\n",
            "Game: 77, Total Reward: 33.000000, Epsilon: 0.100000\n",
            "Game: 78, Total Reward: 29.000000, Epsilon: 0.100000\n",
            "Game: 79, Total Reward: 43.000000, Epsilon: 0.100000\n",
            "Game: 80, Total Reward: 31.000000, Epsilon: 0.100000\n",
            "Game: 81, Total Reward: 31.000000, Epsilon: 0.100000\n",
            "Game: 82, Total Reward: 75.000000, Epsilon: 0.100000\n",
            "Game: 83, Total Reward: 53.000000, Epsilon: 0.100000\n",
            "Game: 84, Total Reward: 44.000000, Epsilon: 0.100000\n",
            "Game: 85, Total Reward: 28.000000, Epsilon: 0.100000\n",
            "Game: 86, Total Reward: 69.000000, Epsilon: 0.100000\n",
            "Game: 87, Total Reward: 44.000000, Epsilon: 0.100000\n",
            "Game: 88, Total Reward: 41.000000, Epsilon: 0.100000\n",
            "Game: 89, Total Reward: 105.000000, Epsilon: 0.100000\n",
            "Game: 90, Total Reward: 71.000000, Epsilon: 0.100000\n",
            "Game: 91, Total Reward: 51.000000, Epsilon: 0.100000\n",
            "Game: 92, Total Reward: 61.000000, Epsilon: 0.100000\n",
            "Game: 93, Total Reward: 115.000000, Epsilon: 0.100000\n",
            "Game: 94, Total Reward: 71.000000, Epsilon: 0.100000\n",
            "Game: 95, Total Reward: 30.000000, Epsilon: 0.100000\n",
            "Game: 96, Total Reward: 82.000000, Epsilon: 0.100000\n",
            "Game: 97, Total Reward: 85.000000, Epsilon: 0.100000\n",
            "Game: 98, Total Reward: 101.000000, Epsilon: 0.100000\n",
            "Game: 99, Total Reward: 93.000000, Epsilon: 0.100000\n",
            "Game: 100, Total Reward: 185.000000, Epsilon: 0.100000\n",
            "Game: 101, Total Reward: 100.000000, Epsilon: 0.100000\n",
            "Game: 102, Total Reward: 115.000000, Epsilon: 0.100000\n",
            "Game: 103, Total Reward: 337.000000, Epsilon: 0.100000\n",
            "Game: 104, Total Reward: 236.000000, Epsilon: 0.100000\n",
            "Game: 105, Total Reward: 189.000000, Epsilon: 0.100000\n",
            "Game: 106, Total Reward: 183.000000, Epsilon: 0.100000\n",
            "Game: 107, Total Reward: 223.000000, Epsilon: 0.100000\n",
            "Game: 108, Total Reward: 153.000000, Epsilon: 0.100000\n",
            "Game: 109, Total Reward: 219.000000, Epsilon: 0.100000\n",
            "Game: 110, Total Reward: 194.000000, Epsilon: 0.100000\n",
            "Game: 111, Total Reward: 172.000000, Epsilon: 0.100000\n",
            "Game: 112, Total Reward: 204.000000, Epsilon: 0.100000\n",
            "Game: 113, Total Reward: 295.000000, Epsilon: 0.100000\n",
            "Game: 114, Total Reward: 248.000000, Epsilon: 0.100000\n",
            "Game: 115, Total Reward: 302.000000, Epsilon: 0.100000\n",
            "Game: 116, Total Reward: 251.000000, Epsilon: 0.100000\n",
            "Game: 117, Total Reward: 245.000000, Epsilon: 0.100000\n",
            "Game: 118, Total Reward: 240.000000, Epsilon: 0.100000\n",
            "Game: 119, Total Reward: 253.000000, Epsilon: 0.100000\n",
            "Game: 120, Total Reward: 358.000000, Epsilon: 0.100000\n",
            "Game: 121, Total Reward: 178.000000, Epsilon: 0.100000\n",
            "Game: 122, Total Reward: 241.000000, Epsilon: 0.100000\n",
            "Game: 123, Total Reward: 202.000000, Epsilon: 0.100000\n",
            "Game: 124, Total Reward: 182.000000, Epsilon: 0.100000\n",
            "Game: 125, Total Reward: 186.000000, Epsilon: 0.100000\n",
            "Game: 126, Total Reward: 293.000000, Epsilon: 0.100000\n",
            "Game: 127, Total Reward: 216.000000, Epsilon: 0.100000\n",
            "Game: 128, Total Reward: 232.000000, Epsilon: 0.100000\n",
            "Game: 129, Total Reward: 164.000000, Epsilon: 0.100000\n",
            "Game: 130, Total Reward: 192.000000, Epsilon: 0.100000\n",
            "Game: 131, Total Reward: 282.000000, Epsilon: 0.100000\n",
            "Game: 132, Total Reward: 145.000000, Epsilon: 0.100000\n",
            "Game: 133, Total Reward: 210.000000, Epsilon: 0.100000\n",
            "Game: 134, Total Reward: 170.000000, Epsilon: 0.100000\n",
            "Game: 135, Total Reward: 208.000000, Epsilon: 0.100000\n",
            "Game: 136, Total Reward: 198.000000, Epsilon: 0.100000\n",
            "Game: 137, Total Reward: 377.000000, Epsilon: 0.100000\n",
            "Game: 138, Total Reward: 145.000000, Epsilon: 0.100000\n",
            "Game: 139, Total Reward: 155.000000, Epsilon: 0.100000\n",
            "Game: 140, Total Reward: 203.000000, Epsilon: 0.100000\n",
            "Game: 141, Total Reward: 212.000000, Epsilon: 0.100000\n",
            "Game: 142, Total Reward: 164.000000, Epsilon: 0.100000\n",
            "Game: 143, Total Reward: 138.000000, Epsilon: 0.100000\n",
            "Game: 144, Total Reward: 142.000000, Epsilon: 0.100000\n",
            "Game: 145, Total Reward: 180.000000, Epsilon: 0.100000\n",
            "Game: 146, Total Reward: 170.000000, Epsilon: 0.100000\n",
            "Game: 147, Total Reward: 136.000000, Epsilon: 0.100000\n",
            "Game: 148, Total Reward: 218.000000, Epsilon: 0.100000\n",
            "Game: 149, Total Reward: 144.000000, Epsilon: 0.100000\n",
            "Game: 150, Total Reward: 165.000000, Epsilon: 0.100000\n",
            "Game: 151, Total Reward: 137.000000, Epsilon: 0.100000\n",
            "Game: 152, Total Reward: 142.000000, Epsilon: 0.100000\n",
            "Game: 153, Total Reward: 203.000000, Epsilon: 0.100000\n",
            "Game: 154, Total Reward: 179.000000, Epsilon: 0.100000\n",
            "Game: 155, Total Reward: 194.000000, Epsilon: 0.100000\n",
            "Game: 156, Total Reward: 141.000000, Epsilon: 0.100000\n",
            "Game: 157, Total Reward: 214.000000, Epsilon: 0.100000\n",
            "Game: 158, Total Reward: 155.000000, Epsilon: 0.100000\n",
            "Game: 159, Total Reward: 138.000000, Epsilon: 0.100000\n",
            "Game: 160, Total Reward: 136.000000, Epsilon: 0.100000\n",
            "Game: 161, Total Reward: 152.000000, Epsilon: 0.100000\n",
            "Game: 162, Total Reward: 270.000000, Epsilon: 0.100000\n",
            "Game: 163, Total Reward: 237.000000, Epsilon: 0.100000\n",
            "Game: 164, Total Reward: 129.000000, Epsilon: 0.100000\n",
            "Game: 165, Total Reward: 120.000000, Epsilon: 0.100000\n",
            "Game: 166, Total Reward: 139.000000, Epsilon: 0.100000\n",
            "Game: 167, Total Reward: 142.000000, Epsilon: 0.100000\n",
            "Game: 168, Total Reward: 164.000000, Epsilon: 0.100000\n",
            "Game: 169, Total Reward: 154.000000, Epsilon: 0.100000\n",
            "Game: 170, Total Reward: 144.000000, Epsilon: 0.100000\n",
            "Game: 171, Total Reward: 159.000000, Epsilon: 0.100000\n",
            "Game: 172, Total Reward: 172.000000, Epsilon: 0.100000\n",
            "Game: 173, Total Reward: 232.000000, Epsilon: 0.100000\n",
            "Game: 174, Total Reward: 138.000000, Epsilon: 0.100000\n",
            "Game: 175, Total Reward: 172.000000, Epsilon: 0.100000\n",
            "Game: 176, Total Reward: 143.000000, Epsilon: 0.100000\n",
            "Game: 177, Total Reward: 194.000000, Epsilon: 0.100000\n",
            "Game: 178, Total Reward: 126.000000, Epsilon: 0.100000\n",
            "Game: 179, Total Reward: 141.000000, Epsilon: 0.100000\n",
            "Game: 180, Total Reward: 181.000000, Epsilon: 0.100000\n",
            "Game: 181, Total Reward: 194.000000, Epsilon: 0.100000\n",
            "Game: 182, Total Reward: 146.000000, Epsilon: 0.100000\n",
            "Game: 183, Total Reward: 238.000000, Epsilon: 0.100000\n",
            "Game: 184, Total Reward: 141.000000, Epsilon: 0.100000\n",
            "Game: 185, Total Reward: 211.000000, Epsilon: 0.100000\n",
            "Game: 186, Total Reward: 164.000000, Epsilon: 0.100000\n",
            "Game: 187, Total Reward: 145.000000, Epsilon: 0.100000\n",
            "Game: 188, Total Reward: 162.000000, Epsilon: 0.100000\n",
            "Game: 189, Total Reward: 183.000000, Epsilon: 0.100000\n",
            "Game: 190, Total Reward: 154.000000, Epsilon: 0.100000\n",
            "Game: 191, Total Reward: 152.000000, Epsilon: 0.100000\n",
            "Game: 192, Total Reward: 230.000000, Epsilon: 0.100000\n",
            "Game: 193, Total Reward: 154.000000, Epsilon: 0.100000\n",
            "Game: 194, Total Reward: 238.000000, Epsilon: 0.100000\n",
            "Game: 195, Total Reward: 164.000000, Epsilon: 0.100000\n",
            "Game: 196, Total Reward: 153.000000, Epsilon: 0.100000\n",
            "Game: 197, Total Reward: 139.000000, Epsilon: 0.100000\n",
            "Game: 198, Total Reward: 167.000000, Epsilon: 0.100000\n",
            "Game: 199, Total Reward: 168.000000, Epsilon: 0.100000\n",
            "Game: 200, Total Reward: 162.000000, Epsilon: 0.100000\n",
            "Game: 1, Total Reward: 23.000000, Epsilon: 0.891109\n",
            "Game: 2, Total Reward: 26.000000, Epsilon: 0.782224\n",
            "Game: 3, Total Reward: 13.000000, Epsilon: 0.732877\n",
            "Game: 4, Total Reward: 13.000000, Epsilon: 0.686643\n",
            "Game: 5, Total Reward: 22.000000, Epsilon: 0.614949\n",
            "Game: 6, Total Reward: 9.000000, Epsilon: 0.587823\n",
            "Game: 7, Total Reward: 11.000000, Epsilon: 0.556289\n",
            "Game: 8, Total Reward: 17.000000, Epsilon: 0.510849\n",
            "Game: 9, Total Reward: 18.000000, Epsilon: 0.466776\n",
            "Game: 10, Total Reward: 12.000000, Epsilon: 0.439527\n",
            "Game: 11, Total Reward: 13.000000, Epsilon: 0.411799\n",
            "Game: 12, Total Reward: 11.000000, Epsilon: 0.389708\n",
            "Game: 13, Total Reward: 11.000000, Epsilon: 0.368802\n",
            "Game: 14, Total Reward: 9.000000, Epsilon: 0.352534\n",
            "Game: 15, Total Reward: 10.000000, Epsilon: 0.335298\n",
            "Game: 16, Total Reward: 9.000000, Epsilon: 0.320508\n",
            "Game: 17, Total Reward: 14.000000, Epsilon: 0.298788\n",
            "Game: 18, Total Reward: 13.000000, Epsilon: 0.279938\n",
            "Game: 19, Total Reward: 21.000000, Epsilon: 0.251969\n",
            "Game: 20, Total Reward: 37.000000, Epsilon: 0.209315\n",
            "Game: 21, Total Reward: 13.000000, Epsilon: 0.196111\n",
            "Game: 22, Total Reward: 10.000000, Epsilon: 0.186523\n",
            "Game: 23, Total Reward: 12.000000, Epsilon: 0.175634\n",
            "Game: 24, Total Reward: 9.000000, Epsilon: 0.167887\n",
            "Game: 25, Total Reward: 8.000000, Epsilon: 0.161288\n",
            "Game: 26, Total Reward: 10.000000, Epsilon: 0.153402\n",
            "Game: 27, Total Reward: 58.000000, Epsilon: 0.114702\n",
            "Game: 28, Total Reward: 25.000000, Epsilon: 0.101192\n",
            "Game: 29, Total Reward: 20.000000, Epsilon: 0.100000\n",
            "Game: 30, Total Reward: 12.000000, Epsilon: 0.100000\n",
            "Game: 31, Total Reward: 44.000000, Epsilon: 0.100000\n",
            "Game: 32, Total Reward: 75.000000, Epsilon: 0.100000\n",
            "Game: 33, Total Reward: 104.000000, Epsilon: 0.100000\n",
            "Game: 34, Total Reward: 87.000000, Epsilon: 0.100000\n",
            "Game: 35, Total Reward: 15.000000, Epsilon: 0.100000\n",
            "Game: 36, Total Reward: 63.000000, Epsilon: 0.100000\n",
            "Game: 37, Total Reward: 54.000000, Epsilon: 0.100000\n",
            "Game: 38, Total Reward: 56.000000, Epsilon: 0.100000\n",
            "Game: 39, Total Reward: 17.000000, Epsilon: 0.100000\n",
            "Game: 40, Total Reward: 13.000000, Epsilon: 0.100000\n",
            "Game: 41, Total Reward: 16.000000, Epsilon: 0.100000\n",
            "Game: 42, Total Reward: 14.000000, Epsilon: 0.100000\n",
            "Game: 43, Total Reward: 22.000000, Epsilon: 0.100000\n",
            "Game: 44, Total Reward: 65.000000, Epsilon: 0.100000\n",
            "Game: 45, Total Reward: 42.000000, Epsilon: 0.100000\n",
            "Game: 46, Total Reward: 25.000000, Epsilon: 0.100000\n",
            "Game: 47, Total Reward: 67.000000, Epsilon: 0.100000\n",
            "Game: 48, Total Reward: 39.000000, Epsilon: 0.100000\n",
            "Game: 49, Total Reward: 83.000000, Epsilon: 0.100000\n",
            "Game: 50, Total Reward: 57.000000, Epsilon: 0.100000\n",
            "Game: 51, Total Reward: 75.000000, Epsilon: 0.100000\n",
            "Game: 52, Total Reward: 59.000000, Epsilon: 0.100000\n",
            "Game: 53, Total Reward: 60.000000, Epsilon: 0.100000\n",
            "Game: 54, Total Reward: 169.000000, Epsilon: 0.100000\n",
            "Game: 55, Total Reward: 83.000000, Epsilon: 0.100000\n",
            "Game: 56, Total Reward: 66.000000, Epsilon: 0.100000\n",
            "Game: 57, Total Reward: 128.000000, Epsilon: 0.100000\n",
            "Game: 58, Total Reward: 198.000000, Epsilon: 0.100000\n",
            "Game: 59, Total Reward: 117.000000, Epsilon: 0.100000\n",
            "Game: 60, Total Reward: 98.000000, Epsilon: 0.100000\n",
            "Game: 61, Total Reward: 116.000000, Epsilon: 0.100000\n",
            "Game: 62, Total Reward: 94.000000, Epsilon: 0.100000\n",
            "Game: 63, Total Reward: 109.000000, Epsilon: 0.100000\n",
            "Game: 64, Total Reward: 96.000000, Epsilon: 0.100000\n",
            "Game: 65, Total Reward: 130.000000, Epsilon: 0.100000\n",
            "Game: 66, Total Reward: 74.000000, Epsilon: 0.100000\n",
            "Game: 67, Total Reward: 170.000000, Epsilon: 0.100000\n",
            "Game: 68, Total Reward: 98.000000, Epsilon: 0.100000\n",
            "Game: 69, Total Reward: 236.000000, Epsilon: 0.100000\n",
            "Game: 70, Total Reward: 314.000000, Epsilon: 0.100000\n",
            "Game: 71, Total Reward: 211.000000, Epsilon: 0.100000\n",
            "Game: 72, Total Reward: 154.000000, Epsilon: 0.100000\n",
            "Game: 73, Total Reward: 165.000000, Epsilon: 0.100000\n",
            "Game: 74, Total Reward: 332.000000, Epsilon: 0.100000\n",
            "Game: 75, Total Reward: 141.000000, Epsilon: 0.100000\n",
            "Game: 76, Total Reward: 183.000000, Epsilon: 0.100000\n",
            "Game: 77, Total Reward: 192.000000, Epsilon: 0.100000\n",
            "Game: 78, Total Reward: 246.000000, Epsilon: 0.100000\n",
            "Game: 79, Total Reward: 165.000000, Epsilon: 0.100000\n",
            "Game: 80, Total Reward: 220.000000, Epsilon: 0.100000\n",
            "Game: 81, Total Reward: 214.000000, Epsilon: 0.100000\n",
            "Game: 82, Total Reward: 264.000000, Epsilon: 0.100000\n",
            "Game: 83, Total Reward: 500.000000, Epsilon: 0.100000\n",
            "Game: 84, Total Reward: 398.000000, Epsilon: 0.100000\n",
            "Game: 85, Total Reward: 397.000000, Epsilon: 0.100000\n",
            "Game: 86, Total Reward: 353.000000, Epsilon: 0.100000\n",
            "Game: 87, Total Reward: 265.000000, Epsilon: 0.100000\n",
            "Game: 88, Total Reward: 274.000000, Epsilon: 0.100000\n",
            "Game: 89, Total Reward: 349.000000, Epsilon: 0.100000\n",
            "Game: 90, Total Reward: 469.000000, Epsilon: 0.100000\n",
            "Game: 91, Total Reward: 307.000000, Epsilon: 0.100000\n",
            "Game: 92, Total Reward: 381.000000, Epsilon: 0.100000\n",
            "Game: 93, Total Reward: 310.000000, Epsilon: 0.100000\n",
            "Game: 94, Total Reward: 296.000000, Epsilon: 0.100000\n",
            "Game: 95, Total Reward: 420.000000, Epsilon: 0.100000\n",
            "Game: 96, Total Reward: 321.000000, Epsilon: 0.100000\n",
            "Game: 97, Total Reward: 285.000000, Epsilon: 0.100000\n",
            "Game: 98, Total Reward: 269.000000, Epsilon: 0.100000\n",
            "Game: 99, Total Reward: 305.000000, Epsilon: 0.100000\n",
            "Game: 100, Total Reward: 249.000000, Epsilon: 0.100000\n",
            "Game: 101, Total Reward: 309.000000, Epsilon: 0.100000\n",
            "Game: 102, Total Reward: 337.000000, Epsilon: 0.100000\n",
            "Game: 103, Total Reward: 280.000000, Epsilon: 0.100000\n",
            "Game: 104, Total Reward: 309.000000, Epsilon: 0.100000\n",
            "Game: 105, Total Reward: 235.000000, Epsilon: 0.100000\n",
            "Game: 106, Total Reward: 276.000000, Epsilon: 0.100000\n",
            "Game: 107, Total Reward: 258.000000, Epsilon: 0.100000\n",
            "Game: 108, Total Reward: 302.000000, Epsilon: 0.100000\n",
            "Game: 109, Total Reward: 269.000000, Epsilon: 0.100000\n",
            "Game: 110, Total Reward: 290.000000, Epsilon: 0.100000\n",
            "Game: 111, Total Reward: 252.000000, Epsilon: 0.100000\n",
            "Game: 112, Total Reward: 273.000000, Epsilon: 0.100000\n",
            "Game: 113, Total Reward: 241.000000, Epsilon: 0.100000\n",
            "Game: 114, Total Reward: 251.000000, Epsilon: 0.100000\n",
            "Game: 115, Total Reward: 242.000000, Epsilon: 0.100000\n",
            "Game: 116, Total Reward: 274.000000, Epsilon: 0.100000\n",
            "Game: 117, Total Reward: 276.000000, Epsilon: 0.100000\n",
            "Game: 118, Total Reward: 274.000000, Epsilon: 0.100000\n",
            "Game: 119, Total Reward: 258.000000, Epsilon: 0.100000\n",
            "Game: 120, Total Reward: 274.000000, Epsilon: 0.100000\n",
            "Game: 121, Total Reward: 208.000000, Epsilon: 0.100000\n",
            "Game: 122, Total Reward: 225.000000, Epsilon: 0.100000\n",
            "Game: 123, Total Reward: 249.000000, Epsilon: 0.100000\n",
            "Game: 124, Total Reward: 255.000000, Epsilon: 0.100000\n",
            "Game: 125, Total Reward: 241.000000, Epsilon: 0.100000\n",
            "Game: 126, Total Reward: 225.000000, Epsilon: 0.100000\n",
            "Game: 127, Total Reward: 195.000000, Epsilon: 0.100000\n",
            "Game: 128, Total Reward: 237.000000, Epsilon: 0.100000\n",
            "Game: 129, Total Reward: 229.000000, Epsilon: 0.100000\n",
            "Game: 130, Total Reward: 237.000000, Epsilon: 0.100000\n",
            "Game: 131, Total Reward: 270.000000, Epsilon: 0.100000\n",
            "Game: 132, Total Reward: 251.000000, Epsilon: 0.100000\n",
            "Game: 133, Total Reward: 224.000000, Epsilon: 0.100000\n",
            "Game: 134, Total Reward: 188.000000, Epsilon: 0.100000\n",
            "Game: 135, Total Reward: 250.000000, Epsilon: 0.100000\n",
            "Game: 136, Total Reward: 256.000000, Epsilon: 0.100000\n",
            "Game: 137, Total Reward: 211.000000, Epsilon: 0.100000\n",
            "Game: 138, Total Reward: 161.000000, Epsilon: 0.100000\n",
            "Game: 139, Total Reward: 336.000000, Epsilon: 0.100000\n",
            "Game: 140, Total Reward: 217.000000, Epsilon: 0.100000\n",
            "Game: 141, Total Reward: 225.000000, Epsilon: 0.100000\n",
            "Game: 142, Total Reward: 173.000000, Epsilon: 0.100000\n",
            "Game: 143, Total Reward: 184.000000, Epsilon: 0.100000\n",
            "Game: 144, Total Reward: 196.000000, Epsilon: 0.100000\n",
            "Game: 145, Total Reward: 135.000000, Epsilon: 0.100000\n",
            "Game: 146, Total Reward: 189.000000, Epsilon: 0.100000\n",
            "Game: 147, Total Reward: 198.000000, Epsilon: 0.100000\n",
            "Game: 148, Total Reward: 248.000000, Epsilon: 0.100000\n",
            "Game: 149, Total Reward: 156.000000, Epsilon: 0.100000\n",
            "Game: 150, Total Reward: 163.000000, Epsilon: 0.100000\n",
            "Game: 151, Total Reward: 155.000000, Epsilon: 0.100000\n",
            "Game: 152, Total Reward: 277.000000, Epsilon: 0.100000\n",
            "Game: 153, Total Reward: 154.000000, Epsilon: 0.100000\n",
            "Game: 154, Total Reward: 183.000000, Epsilon: 0.100000\n",
            "Game: 155, Total Reward: 178.000000, Epsilon: 0.100000\n",
            "Game: 156, Total Reward: 144.000000, Epsilon: 0.100000\n",
            "Game: 157, Total Reward: 195.000000, Epsilon: 0.100000\n",
            "Game: 158, Total Reward: 240.000000, Epsilon: 0.100000\n",
            "Game: 159, Total Reward: 228.000000, Epsilon: 0.100000\n",
            "Game: 160, Total Reward: 175.000000, Epsilon: 0.100000\n",
            "Game: 161, Total Reward: 157.000000, Epsilon: 0.100000\n",
            "Game: 162, Total Reward: 365.000000, Epsilon: 0.100000\n",
            "Game: 163, Total Reward: 117.000000, Epsilon: 0.100000\n",
            "Game: 164, Total Reward: 118.000000, Epsilon: 0.100000\n",
            "Game: 165, Total Reward: 393.000000, Epsilon: 0.100000\n",
            "Game: 166, Total Reward: 323.000000, Epsilon: 0.100000\n",
            "Game: 167, Total Reward: 143.000000, Epsilon: 0.100000\n",
            "Game: 168, Total Reward: 113.000000, Epsilon: 0.100000\n",
            "Game: 169, Total Reward: 266.000000, Epsilon: 0.100000\n",
            "Game: 170, Total Reward: 500.000000, Epsilon: 0.100000\n",
            "Game: 171, Total Reward: 172.000000, Epsilon: 0.100000\n",
            "Game: 172, Total Reward: 140.000000, Epsilon: 0.100000\n",
            "Game: 173, Total Reward: 131.000000, Epsilon: 0.100000\n",
            "Game: 174, Total Reward: 37.000000, Epsilon: 0.100000\n",
            "Game: 175, Total Reward: 116.000000, Epsilon: 0.100000\n",
            "Game: 176, Total Reward: 162.000000, Epsilon: 0.100000\n",
            "Game: 177, Total Reward: 139.000000, Epsilon: 0.100000\n",
            "Game: 178, Total Reward: 140.000000, Epsilon: 0.100000\n",
            "Game: 179, Total Reward: 124.000000, Epsilon: 0.100000\n",
            "Game: 180, Total Reward: 149.000000, Epsilon: 0.100000\n",
            "Game: 181, Total Reward: 177.000000, Epsilon: 0.100000\n",
            "Game: 182, Total Reward: 136.000000, Epsilon: 0.100000\n",
            "Game: 183, Total Reward: 126.000000, Epsilon: 0.100000\n",
            "Game: 184, Total Reward: 136.000000, Epsilon: 0.100000\n",
            "Game: 185, Total Reward: 19.000000, Epsilon: 0.100000\n",
            "Game: 186, Total Reward: 124.000000, Epsilon: 0.100000\n",
            "Game: 187, Total Reward: 153.000000, Epsilon: 0.100000\n",
            "Game: 188, Total Reward: 115.000000, Epsilon: 0.100000\n",
            "Game: 189, Total Reward: 230.000000, Epsilon: 0.100000\n",
            "Game: 190, Total Reward: 134.000000, Epsilon: 0.100000\n",
            "Game: 191, Total Reward: 134.000000, Epsilon: 0.100000\n",
            "Game: 192, Total Reward: 198.000000, Epsilon: 0.100000\n",
            "Game: 193, Total Reward: 117.000000, Epsilon: 0.100000\n",
            "Game: 194, Total Reward: 112.000000, Epsilon: 0.100000\n",
            "Game: 195, Total Reward: 137.000000, Epsilon: 0.100000\n",
            "Game: 196, Total Reward: 111.000000, Epsilon: 0.100000\n",
            "Game: 197, Total Reward: 11.000000, Epsilon: 0.100000\n",
            "Game: 198, Total Reward: 110.000000, Epsilon: 0.100000\n",
            "Game: 199, Total Reward: 115.000000, Epsilon: 0.100000\n",
            "Game: 200, Total Reward: 500.000000, Epsilon: 0.100000\n",
            "Game: 1, Total Reward: 20.000000, Epsilon: 0.904610\n",
            "Game: 2, Total Reward: 19.000000, Epsilon: 0.822432\n",
            "Game: 3, Total Reward: 55.000000, Epsilon: 0.624266\n",
            "Game: 4, Total Reward: 22.000000, Epsilon: 0.559084\n",
            "Game: 5, Total Reward: 20.000000, Epsilon: 0.505754\n",
            "Game: 6, Total Reward: 12.000000, Epsilon: 0.476229\n",
            "Game: 7, Total Reward: 27.000000, Epsilon: 0.415948\n",
            "Game: 8, Total Reward: 10.000000, Epsilon: 0.395612\n",
            "Game: 9, Total Reward: 14.000000, Epsilon: 0.368802\n",
            "Game: 10, Total Reward: 12.000000, Epsilon: 0.347272\n",
            "Game: 11, Total Reward: 17.000000, Epsilon: 0.318906\n",
            "Game: 12, Total Reward: 13.000000, Epsilon: 0.298788\n",
            "Game: 13, Total Reward: 13.000000, Epsilon: 0.279938\n",
            "Game: 14, Total Reward: 15.000000, Epsilon: 0.259662\n",
            "Game: 15, Total Reward: 10.000000, Epsilon: 0.246967\n",
            "Game: 16, Total Reward: 10.000000, Epsilon: 0.234893\n",
            "Game: 17, Total Reward: 9.000000, Epsilon: 0.224532\n",
            "Game: 18, Total Reward: 12.000000, Epsilon: 0.211424\n",
            "Game: 19, Total Reward: 9.000000, Epsilon: 0.202098\n",
            "Game: 20, Total Reward: 10.000000, Epsilon: 0.192218\n",
            "Game: 21, Total Reward: 12.000000, Epsilon: 0.180997\n",
            "Game: 22, Total Reward: 10.000000, Epsilon: 0.172148\n",
            "Game: 23, Total Reward: 10.000000, Epsilon: 0.163731\n",
            "Game: 24, Total Reward: 9.000000, Epsilon: 0.156509\n",
            "Game: 25, Total Reward: 12.000000, Epsilon: 0.147373\n",
            "Game: 26, Total Reward: 13.000000, Epsilon: 0.138076\n",
            "Game: 27, Total Reward: 9.000000, Epsilon: 0.131985\n",
            "Game: 28, Total Reward: 11.000000, Epsilon: 0.124905\n",
            "Game: 29, Total Reward: 11.000000, Epsilon: 0.118204\n",
            "Game: 30, Total Reward: 12.000000, Epsilon: 0.111304\n",
            "Game: 31, Total Reward: 12.000000, Epsilon: 0.104806\n",
            "Game: 32, Total Reward: 11.000000, Epsilon: 0.100000\n",
            "Game: 33, Total Reward: 11.000000, Epsilon: 0.100000\n",
            "Game: 34, Total Reward: 14.000000, Epsilon: 0.100000\n",
            "Game: 35, Total Reward: 11.000000, Epsilon: 0.100000\n",
            "Game: 36, Total Reward: 13.000000, Epsilon: 0.100000\n",
            "Game: 37, Total Reward: 13.000000, Epsilon: 0.100000\n",
            "Game: 38, Total Reward: 19.000000, Epsilon: 0.100000\n",
            "Game: 39, Total Reward: 17.000000, Epsilon: 0.100000\n",
            "Game: 40, Total Reward: 11.000000, Epsilon: 0.100000\n",
            "Game: 41, Total Reward: 12.000000, Epsilon: 0.100000\n",
            "Game: 42, Total Reward: 29.000000, Epsilon: 0.100000\n",
            "Game: 43, Total Reward: 43.000000, Epsilon: 0.100000\n",
            "Game: 44, Total Reward: 28.000000, Epsilon: 0.100000\n",
            "Game: 45, Total Reward: 26.000000, Epsilon: 0.100000\n",
            "Game: 46, Total Reward: 25.000000, Epsilon: 0.100000\n",
            "Game: 47, Total Reward: 44.000000, Epsilon: 0.100000\n",
            "Game: 48, Total Reward: 34.000000, Epsilon: 0.100000\n",
            "Game: 49, Total Reward: 30.000000, Epsilon: 0.100000\n",
            "Game: 50, Total Reward: 52.000000, Epsilon: 0.100000\n",
            "Game: 51, Total Reward: 33.000000, Epsilon: 0.100000\n",
            "Game: 52, Total Reward: 24.000000, Epsilon: 0.100000\n",
            "Game: 53, Total Reward: 69.000000, Epsilon: 0.100000\n",
            "Game: 54, Total Reward: 69.000000, Epsilon: 0.100000\n",
            "Game: 55, Total Reward: 97.000000, Epsilon: 0.100000\n",
            "Game: 56, Total Reward: 129.000000, Epsilon: 0.100000\n",
            "Game: 57, Total Reward: 144.000000, Epsilon: 0.100000\n",
            "Game: 58, Total Reward: 153.000000, Epsilon: 0.100000\n",
            "Game: 59, Total Reward: 144.000000, Epsilon: 0.100000\n",
            "Game: 60, Total Reward: 160.000000, Epsilon: 0.100000\n",
            "Game: 61, Total Reward: 141.000000, Epsilon: 0.100000\n",
            "Game: 62, Total Reward: 134.000000, Epsilon: 0.100000\n",
            "Game: 63, Total Reward: 144.000000, Epsilon: 0.100000\n",
            "Game: 64, Total Reward: 131.000000, Epsilon: 0.100000\n",
            "Game: 65, Total Reward: 183.000000, Epsilon: 0.100000\n",
            "Game: 66, Total Reward: 130.000000, Epsilon: 0.100000\n",
            "Game: 67, Total Reward: 181.000000, Epsilon: 0.100000\n",
            "Game: 68, Total Reward: 179.000000, Epsilon: 0.100000\n",
            "Game: 69, Total Reward: 158.000000, Epsilon: 0.100000\n",
            "Game: 70, Total Reward: 141.000000, Epsilon: 0.100000\n",
            "Game: 71, Total Reward: 206.000000, Epsilon: 0.100000\n",
            "Game: 72, Total Reward: 192.000000, Epsilon: 0.100000\n",
            "Game: 73, Total Reward: 205.000000, Epsilon: 0.100000\n",
            "Game: 74, Total Reward: 148.000000, Epsilon: 0.100000\n",
            "Game: 75, Total Reward: 178.000000, Epsilon: 0.100000\n",
            "Game: 76, Total Reward: 156.000000, Epsilon: 0.100000\n",
            "Game: 77, Total Reward: 180.000000, Epsilon: 0.100000\n",
            "Game: 78, Total Reward: 180.000000, Epsilon: 0.100000\n",
            "Game: 79, Total Reward: 169.000000, Epsilon: 0.100000\n",
            "Game: 80, Total Reward: 136.000000, Epsilon: 0.100000\n",
            "Game: 81, Total Reward: 179.000000, Epsilon: 0.100000\n",
            "Game: 82, Total Reward: 186.000000, Epsilon: 0.100000\n",
            "Game: 83, Total Reward: 166.000000, Epsilon: 0.100000\n",
            "Game: 84, Total Reward: 198.000000, Epsilon: 0.100000\n",
            "Game: 85, Total Reward: 151.000000, Epsilon: 0.100000\n",
            "Game: 86, Total Reward: 141.000000, Epsilon: 0.100000\n",
            "Game: 87, Total Reward: 184.000000, Epsilon: 0.100000\n",
            "Game: 88, Total Reward: 160.000000, Epsilon: 0.100000\n",
            "Game: 89, Total Reward: 138.000000, Epsilon: 0.100000\n",
            "Game: 90, Total Reward: 134.000000, Epsilon: 0.100000\n",
            "Game: 91, Total Reward: 164.000000, Epsilon: 0.100000\n",
            "Game: 92, Total Reward: 189.000000, Epsilon: 0.100000\n",
            "Game: 93, Total Reward: 201.000000, Epsilon: 0.100000\n",
            "Game: 94, Total Reward: 121.000000, Epsilon: 0.100000\n",
            "Game: 95, Total Reward: 140.000000, Epsilon: 0.100000\n",
            "Game: 96, Total Reward: 148.000000, Epsilon: 0.100000\n",
            "Game: 97, Total Reward: 214.000000, Epsilon: 0.100000\n",
            "Game: 98, Total Reward: 155.000000, Epsilon: 0.100000\n",
            "Game: 99, Total Reward: 143.000000, Epsilon: 0.100000\n",
            "Game: 100, Total Reward: 153.000000, Epsilon: 0.100000\n",
            "Game: 101, Total Reward: 137.000000, Epsilon: 0.100000\n",
            "Game: 102, Total Reward: 147.000000, Epsilon: 0.100000\n",
            "Game: 103, Total Reward: 183.000000, Epsilon: 0.100000\n",
            "Game: 104, Total Reward: 125.000000, Epsilon: 0.100000\n",
            "Game: 105, Total Reward: 162.000000, Epsilon: 0.100000\n",
            "Game: 106, Total Reward: 134.000000, Epsilon: 0.100000\n",
            "Game: 107, Total Reward: 149.000000, Epsilon: 0.100000\n",
            "Game: 108, Total Reward: 152.000000, Epsilon: 0.100000\n",
            "Game: 109, Total Reward: 132.000000, Epsilon: 0.100000\n",
            "Game: 110, Total Reward: 145.000000, Epsilon: 0.100000\n",
            "Game: 111, Total Reward: 125.000000, Epsilon: 0.100000\n",
            "Game: 112, Total Reward: 323.000000, Epsilon: 0.100000\n",
            "Game: 113, Total Reward: 140.000000, Epsilon: 0.100000\n",
            "Game: 114, Total Reward: 152.000000, Epsilon: 0.100000\n",
            "Game: 115, Total Reward: 192.000000, Epsilon: 0.100000\n",
            "Game: 116, Total Reward: 234.000000, Epsilon: 0.100000\n",
            "Game: 117, Total Reward: 151.000000, Epsilon: 0.100000\n",
            "Game: 118, Total Reward: 186.000000, Epsilon: 0.100000\n",
            "Game: 119, Total Reward: 206.000000, Epsilon: 0.100000\n",
            "Game: 120, Total Reward: 196.000000, Epsilon: 0.100000\n",
            "Game: 121, Total Reward: 134.000000, Epsilon: 0.100000\n",
            "Game: 122, Total Reward: 204.000000, Epsilon: 0.100000\n",
            "Game: 123, Total Reward: 163.000000, Epsilon: 0.100000\n",
            "Game: 124, Total Reward: 151.000000, Epsilon: 0.100000\n",
            "Game: 125, Total Reward: 132.000000, Epsilon: 0.100000\n",
            "Game: 126, Total Reward: 146.000000, Epsilon: 0.100000\n",
            "Game: 127, Total Reward: 158.000000, Epsilon: 0.100000\n",
            "Game: 128, Total Reward: 177.000000, Epsilon: 0.100000\n",
            "Game: 129, Total Reward: 170.000000, Epsilon: 0.100000\n",
            "Game: 130, Total Reward: 298.000000, Epsilon: 0.100000\n",
            "Game: 131, Total Reward: 144.000000, Epsilon: 0.100000\n",
            "Game: 132, Total Reward: 158.000000, Epsilon: 0.100000\n",
            "Game: 133, Total Reward: 170.000000, Epsilon: 0.100000\n",
            "Game: 134, Total Reward: 180.000000, Epsilon: 0.100000\n",
            "Game: 135, Total Reward: 150.000000, Epsilon: 0.100000\n",
            "Game: 136, Total Reward: 169.000000, Epsilon: 0.100000\n",
            "Game: 137, Total Reward: 164.000000, Epsilon: 0.100000\n",
            "Game: 138, Total Reward: 142.000000, Epsilon: 0.100000\n",
            "Game: 139, Total Reward: 130.000000, Epsilon: 0.100000\n",
            "Game: 140, Total Reward: 134.000000, Epsilon: 0.100000\n",
            "Game: 141, Total Reward: 158.000000, Epsilon: 0.100000\n",
            "Game: 142, Total Reward: 150.000000, Epsilon: 0.100000\n",
            "Game: 143, Total Reward: 170.000000, Epsilon: 0.100000\n",
            "Game: 144, Total Reward: 225.000000, Epsilon: 0.100000\n",
            "Game: 145, Total Reward: 136.000000, Epsilon: 0.100000\n",
            "Game: 146, Total Reward: 189.000000, Epsilon: 0.100000\n",
            "Game: 147, Total Reward: 212.000000, Epsilon: 0.100000\n",
            "Game: 148, Total Reward: 233.000000, Epsilon: 0.100000\n",
            "Game: 149, Total Reward: 134.000000, Epsilon: 0.100000\n",
            "Game: 150, Total Reward: 145.000000, Epsilon: 0.100000\n",
            "Game: 151, Total Reward: 133.000000, Epsilon: 0.100000\n",
            "Game: 152, Total Reward: 171.000000, Epsilon: 0.100000\n",
            "Game: 153, Total Reward: 162.000000, Epsilon: 0.100000\n",
            "Game: 154, Total Reward: 184.000000, Epsilon: 0.100000\n",
            "Game: 155, Total Reward: 160.000000, Epsilon: 0.100000\n",
            "Game: 156, Total Reward: 141.000000, Epsilon: 0.100000\n",
            "Game: 157, Total Reward: 153.000000, Epsilon: 0.100000\n",
            "Game: 158, Total Reward: 311.000000, Epsilon: 0.100000\n",
            "Game: 159, Total Reward: 212.000000, Epsilon: 0.100000\n",
            "Game: 160, Total Reward: 235.000000, Epsilon: 0.100000\n",
            "Game: 161, Total Reward: 337.000000, Epsilon: 0.100000\n",
            "Game: 162, Total Reward: 168.000000, Epsilon: 0.100000\n",
            "Game: 163, Total Reward: 142.000000, Epsilon: 0.100000\n",
            "Game: 164, Total Reward: 177.000000, Epsilon: 0.100000\n",
            "Game: 165, Total Reward: 177.000000, Epsilon: 0.100000\n",
            "Game: 166, Total Reward: 166.000000, Epsilon: 0.100000\n",
            "Game: 167, Total Reward: 120.000000, Epsilon: 0.100000\n",
            "Game: 168, Total Reward: 145.000000, Epsilon: 0.100000\n",
            "Game: 169, Total Reward: 162.000000, Epsilon: 0.100000\n",
            "Game: 170, Total Reward: 162.000000, Epsilon: 0.100000\n",
            "Game: 171, Total Reward: 130.000000, Epsilon: 0.100000\n",
            "Game: 172, Total Reward: 148.000000, Epsilon: 0.100000\n",
            "Game: 173, Total Reward: 221.000000, Epsilon: 0.100000\n",
            "Game: 174, Total Reward: 220.000000, Epsilon: 0.100000\n",
            "Game: 175, Total Reward: 146.000000, Epsilon: 0.100000\n",
            "Game: 176, Total Reward: 193.000000, Epsilon: 0.100000\n",
            "Game: 177, Total Reward: 163.000000, Epsilon: 0.100000\n",
            "Game: 178, Total Reward: 136.000000, Epsilon: 0.100000\n",
            "Game: 179, Total Reward: 226.000000, Epsilon: 0.100000\n",
            "Game: 180, Total Reward: 189.000000, Epsilon: 0.100000\n",
            "Game: 181, Total Reward: 149.000000, Epsilon: 0.100000\n",
            "Game: 182, Total Reward: 138.000000, Epsilon: 0.100000\n",
            "Game: 183, Total Reward: 227.000000, Epsilon: 0.100000\n",
            "Game: 184, Total Reward: 187.000000, Epsilon: 0.100000\n",
            "Game: 185, Total Reward: 159.000000, Epsilon: 0.100000\n",
            "Game: 186, Total Reward: 179.000000, Epsilon: 0.100000\n",
            "Game: 187, Total Reward: 186.000000, Epsilon: 0.100000\n",
            "Game: 188, Total Reward: 151.000000, Epsilon: 0.100000\n",
            "Game: 189, Total Reward: 196.000000, Epsilon: 0.100000\n",
            "Game: 190, Total Reward: 169.000000, Epsilon: 0.100000\n",
            "Game: 191, Total Reward: 140.000000, Epsilon: 0.100000\n",
            "Game: 192, Total Reward: 162.000000, Epsilon: 0.100000\n",
            "Game: 193, Total Reward: 233.000000, Epsilon: 0.100000\n",
            "Game: 194, Total Reward: 185.000000, Epsilon: 0.100000\n",
            "Game: 195, Total Reward: 143.000000, Epsilon: 0.100000\n",
            "Game: 196, Total Reward: 159.000000, Epsilon: 0.100000\n",
            "Game: 197, Total Reward: 197.000000, Epsilon: 0.100000\n",
            "Game: 198, Total Reward: 141.000000, Epsilon: 0.100000\n",
            "Game: 199, Total Reward: 180.000000, Epsilon: 0.100000\n",
            "Game: 200, Total Reward: 226.000000, Epsilon: 0.100000\n",
            "Game: 1, Total Reward: 14.000000, Epsilon: 0.932230\n",
            "Game: 2, Total Reward: 12.000000, Epsilon: 0.877809\n",
            "Game: 3, Total Reward: 16.000000, Epsilon: 0.810157\n",
            "Game: 4, Total Reward: 22.000000, Epsilon: 0.725566\n",
            "Game: 5, Total Reward: 14.000000, Epsilon: 0.676395\n",
            "Game: 6, Total Reward: 19.000000, Epsilon: 0.614949\n",
            "Game: 7, Total Reward: 10.000000, Epsilon: 0.584884\n",
            "Game: 8, Total Reward: 9.000000, Epsilon: 0.559084\n",
            "Game: 9, Total Reward: 16.000000, Epsilon: 0.515996\n",
            "Game: 10, Total Reward: 9.000000, Epsilon: 0.493236\n",
            "Game: 11, Total Reward: 10.000000, Epsilon: 0.469121\n",
            "Game: 12, Total Reward: 10.000000, Epsilon: 0.446186\n",
            "Game: 13, Total Reward: 11.000000, Epsilon: 0.422250\n",
            "Game: 14, Total Reward: 10.000000, Epsilon: 0.401606\n",
            "Game: 15, Total Reward: 9.000000, Epsilon: 0.383891\n",
            "Game: 16, Total Reward: 11.000000, Epsilon: 0.363297\n",
            "Game: 17, Total Reward: 14.000000, Epsilon: 0.338677\n",
            "Game: 18, Total Reward: 14.000000, Epsilon: 0.315725\n",
            "Game: 19, Total Reward: 13.000000, Epsilon: 0.295807\n",
            "Game: 20, Total Reward: 9.000000, Epsilon: 0.282759\n",
            "Game: 21, Total Reward: 12.000000, Epsilon: 0.266252\n",
            "Game: 22, Total Reward: 10.000000, Epsilon: 0.253235\n",
            "Game: 23, Total Reward: 13.000000, Epsilon: 0.237260\n",
            "Game: 24, Total Reward: 9.000000, Epsilon: 0.226794\n",
            "Game: 25, Total Reward: 13.000000, Epsilon: 0.212487\n",
            "Game: 26, Total Reward: 12.000000, Epsilon: 0.200082\n",
            "Game: 27, Total Reward: 11.000000, Epsilon: 0.189349\n",
            "Game: 28, Total Reward: 14.000000, Epsilon: 0.176517\n",
            "Game: 29, Total Reward: 17.000000, Epsilon: 0.162098\n",
            "Game: 30, Total Reward: 13.000000, Epsilon: 0.151872\n",
            "Game: 31, Total Reward: 13.000000, Epsilon: 0.142291\n",
            "Game: 32, Total Reward: 11.000000, Epsilon: 0.134658\n",
            "Game: 33, Total Reward: 12.000000, Epsilon: 0.126797\n",
            "Game: 34, Total Reward: 13.000000, Epsilon: 0.118798\n",
            "Game: 35, Total Reward: 16.000000, Epsilon: 0.109642\n",
            "Game: 36, Total Reward: 12.000000, Epsilon: 0.103242\n",
            "Game: 37, Total Reward: 15.000000, Epsilon: 0.100000\n",
            "Game: 38, Total Reward: 16.000000, Epsilon: 0.100000\n",
            "Game: 39, Total Reward: 13.000000, Epsilon: 0.100000\n",
            "Game: 40, Total Reward: 16.000000, Epsilon: 0.100000\n",
            "Game: 41, Total Reward: 12.000000, Epsilon: 0.100000\n",
            "Game: 42, Total Reward: 12.000000, Epsilon: 0.100000\n",
            "Game: 43, Total Reward: 16.000000, Epsilon: 0.100000\n",
            "Game: 44, Total Reward: 15.000000, Epsilon: 0.100000\n",
            "Game: 45, Total Reward: 19.000000, Epsilon: 0.100000\n",
            "Game: 46, Total Reward: 18.000000, Epsilon: 0.100000\n",
            "Game: 47, Total Reward: 19.000000, Epsilon: 0.100000\n",
            "Game: 48, Total Reward: 12.000000, Epsilon: 0.100000\n",
            "Game: 49, Total Reward: 15.000000, Epsilon: 0.100000\n",
            "Game: 50, Total Reward: 11.000000, Epsilon: 0.100000\n",
            "Game: 51, Total Reward: 12.000000, Epsilon: 0.100000\n",
            "Game: 52, Total Reward: 44.000000, Epsilon: 0.100000\n",
            "Game: 53, Total Reward: 24.000000, Epsilon: 0.100000\n",
            "Game: 54, Total Reward: 19.000000, Epsilon: 0.100000\n",
            "Game: 55, Total Reward: 26.000000, Epsilon: 0.100000\n",
            "Game: 56, Total Reward: 22.000000, Epsilon: 0.100000\n",
            "Game: 57, Total Reward: 13.000000, Epsilon: 0.100000\n",
            "Game: 58, Total Reward: 15.000000, Epsilon: 0.100000\n",
            "Game: 59, Total Reward: 50.000000, Epsilon: 0.100000\n",
            "Game: 60, Total Reward: 37.000000, Epsilon: 0.100000\n",
            "Game: 61, Total Reward: 52.000000, Epsilon: 0.100000\n",
            "Game: 62, Total Reward: 21.000000, Epsilon: 0.100000\n",
            "Game: 63, Total Reward: 32.000000, Epsilon: 0.100000\n",
            "Game: 64, Total Reward: 25.000000, Epsilon: 0.100000\n",
            "Game: 65, Total Reward: 52.000000, Epsilon: 0.100000\n",
            "Game: 66, Total Reward: 60.000000, Epsilon: 0.100000\n",
            "Game: 67, Total Reward: 202.000000, Epsilon: 0.100000\n",
            "Game: 68, Total Reward: 38.000000, Epsilon: 0.100000\n",
            "Game: 69, Total Reward: 77.000000, Epsilon: 0.100000\n",
            "Game: 70, Total Reward: 53.000000, Epsilon: 0.100000\n",
            "Game: 71, Total Reward: 66.000000, Epsilon: 0.100000\n",
            "Game: 72, Total Reward: 78.000000, Epsilon: 0.100000\n",
            "Game: 73, Total Reward: 49.000000, Epsilon: 0.100000\n",
            "Game: 74, Total Reward: 58.000000, Epsilon: 0.100000\n",
            "Game: 75, Total Reward: 46.000000, Epsilon: 0.100000\n",
            "Game: 76, Total Reward: 52.000000, Epsilon: 0.100000\n",
            "Game: 77, Total Reward: 48.000000, Epsilon: 0.100000\n",
            "Game: 78, Total Reward: 108.000000, Epsilon: 0.100000\n",
            "Game: 79, Total Reward: 26.000000, Epsilon: 0.100000\n",
            "Game: 80, Total Reward: 68.000000, Epsilon: 0.100000\n",
            "Game: 81, Total Reward: 105.000000, Epsilon: 0.100000\n",
            "Game: 82, Total Reward: 45.000000, Epsilon: 0.100000\n",
            "Game: 83, Total Reward: 50.000000, Epsilon: 0.100000\n",
            "Game: 84, Total Reward: 72.000000, Epsilon: 0.100000\n",
            "Game: 85, Total Reward: 134.000000, Epsilon: 0.100000\n",
            "Game: 86, Total Reward: 89.000000, Epsilon: 0.100000\n",
            "Game: 87, Total Reward: 108.000000, Epsilon: 0.100000\n",
            "Game: 88, Total Reward: 78.000000, Epsilon: 0.100000\n",
            "Game: 89, Total Reward: 86.000000, Epsilon: 0.100000\n",
            "Game: 90, Total Reward: 76.000000, Epsilon: 0.100000\n",
            "Game: 91, Total Reward: 115.000000, Epsilon: 0.100000\n",
            "Game: 92, Total Reward: 71.000000, Epsilon: 0.100000\n",
            "Game: 93, Total Reward: 79.000000, Epsilon: 0.100000\n",
            "Game: 94, Total Reward: 83.000000, Epsilon: 0.100000\n",
            "Game: 95, Total Reward: 75.000000, Epsilon: 0.100000\n",
            "Game: 96, Total Reward: 84.000000, Epsilon: 0.100000\n",
            "Game: 97, Total Reward: 101.000000, Epsilon: 0.100000\n",
            "Game: 98, Total Reward: 115.000000, Epsilon: 0.100000\n",
            "Game: 99, Total Reward: 114.000000, Epsilon: 0.100000\n",
            "Game: 100, Total Reward: 124.000000, Epsilon: 0.100000\n",
            "Game: 101, Total Reward: 119.000000, Epsilon: 0.100000\n",
            "Game: 102, Total Reward: 132.000000, Epsilon: 0.100000\n",
            "Game: 103, Total Reward: 136.000000, Epsilon: 0.100000\n",
            "Game: 104, Total Reward: 124.000000, Epsilon: 0.100000\n",
            "Game: 105, Total Reward: 140.000000, Epsilon: 0.100000\n",
            "Game: 106, Total Reward: 116.000000, Epsilon: 0.100000\n",
            "Game: 107, Total Reward: 134.000000, Epsilon: 0.100000\n",
            "Game: 108, Total Reward: 130.000000, Epsilon: 0.100000\n",
            "Game: 109, Total Reward: 155.000000, Epsilon: 0.100000\n",
            "Game: 110, Total Reward: 163.000000, Epsilon: 0.100000\n",
            "Game: 111, Total Reward: 132.000000, Epsilon: 0.100000\n",
            "Game: 112, Total Reward: 165.000000, Epsilon: 0.100000\n",
            "Game: 113, Total Reward: 125.000000, Epsilon: 0.100000\n",
            "Game: 114, Total Reward: 137.000000, Epsilon: 0.100000\n",
            "Game: 115, Total Reward: 140.000000, Epsilon: 0.100000\n",
            "Game: 116, Total Reward: 146.000000, Epsilon: 0.100000\n",
            "Game: 117, Total Reward: 178.000000, Epsilon: 0.100000\n",
            "Game: 118, Total Reward: 162.000000, Epsilon: 0.100000\n",
            "Game: 119, Total Reward: 145.000000, Epsilon: 0.100000\n",
            "Game: 120, Total Reward: 138.000000, Epsilon: 0.100000\n",
            "Game: 121, Total Reward: 198.000000, Epsilon: 0.100000\n",
            "Game: 122, Total Reward: 193.000000, Epsilon: 0.100000\n",
            "Game: 123, Total Reward: 140.000000, Epsilon: 0.100000\n",
            "Game: 124, Total Reward: 186.000000, Epsilon: 0.100000\n",
            "Game: 125, Total Reward: 154.000000, Epsilon: 0.100000\n",
            "Game: 126, Total Reward: 177.000000, Epsilon: 0.100000\n",
            "Game: 127, Total Reward: 140.000000, Epsilon: 0.100000\n",
            "Game: 128, Total Reward: 156.000000, Epsilon: 0.100000\n",
            "Game: 129, Total Reward: 138.000000, Epsilon: 0.100000\n",
            "Game: 130, Total Reward: 163.000000, Epsilon: 0.100000\n",
            "Game: 131, Total Reward: 128.000000, Epsilon: 0.100000\n",
            "Game: 132, Total Reward: 138.000000, Epsilon: 0.100000\n",
            "Game: 133, Total Reward: 141.000000, Epsilon: 0.100000\n",
            "Game: 134, Total Reward: 135.000000, Epsilon: 0.100000\n",
            "Game: 135, Total Reward: 123.000000, Epsilon: 0.100000\n",
            "Game: 136, Total Reward: 135.000000, Epsilon: 0.100000\n",
            "Game: 137, Total Reward: 168.000000, Epsilon: 0.100000\n",
            "Game: 138, Total Reward: 144.000000, Epsilon: 0.100000\n",
            "Game: 139, Total Reward: 141.000000, Epsilon: 0.100000\n",
            "Game: 140, Total Reward: 147.000000, Epsilon: 0.100000\n",
            "Game: 141, Total Reward: 143.000000, Epsilon: 0.100000\n",
            "Game: 142, Total Reward: 149.000000, Epsilon: 0.100000\n",
            "Game: 143, Total Reward: 142.000000, Epsilon: 0.100000\n",
            "Game: 144, Total Reward: 134.000000, Epsilon: 0.100000\n",
            "Game: 145, Total Reward: 126.000000, Epsilon: 0.100000\n",
            "Game: 146, Total Reward: 147.000000, Epsilon: 0.100000\n",
            "Game: 147, Total Reward: 135.000000, Epsilon: 0.100000\n",
            "Game: 148, Total Reward: 130.000000, Epsilon: 0.100000\n",
            "Game: 149, Total Reward: 138.000000, Epsilon: 0.100000\n",
            "Game: 150, Total Reward: 132.000000, Epsilon: 0.100000\n",
            "Game: 151, Total Reward: 168.000000, Epsilon: 0.100000\n",
            "Game: 152, Total Reward: 133.000000, Epsilon: 0.100000\n",
            "Game: 153, Total Reward: 137.000000, Epsilon: 0.100000\n",
            "Game: 154, Total Reward: 158.000000, Epsilon: 0.100000\n",
            "Game: 155, Total Reward: 136.000000, Epsilon: 0.100000\n",
            "Game: 156, Total Reward: 152.000000, Epsilon: 0.100000\n",
            "Game: 157, Total Reward: 131.000000, Epsilon: 0.100000\n",
            "Game: 158, Total Reward: 155.000000, Epsilon: 0.100000\n",
            "Game: 159, Total Reward: 138.000000, Epsilon: 0.100000\n",
            "Game: 160, Total Reward: 142.000000, Epsilon: 0.100000\n",
            "Game: 161, Total Reward: 130.000000, Epsilon: 0.100000\n",
            "Game: 162, Total Reward: 134.000000, Epsilon: 0.100000\n",
            "Game: 163, Total Reward: 148.000000, Epsilon: 0.100000\n",
            "Game: 164, Total Reward: 167.000000, Epsilon: 0.100000\n",
            "Game: 165, Total Reward: 182.000000, Epsilon: 0.100000\n",
            "Game: 166, Total Reward: 135.000000, Epsilon: 0.100000\n",
            "Game: 167, Total Reward: 176.000000, Epsilon: 0.100000\n",
            "Game: 168, Total Reward: 127.000000, Epsilon: 0.100000\n",
            "Game: 169, Total Reward: 169.000000, Epsilon: 0.100000\n",
            "Game: 170, Total Reward: 122.000000, Epsilon: 0.100000\n",
            "Game: 171, Total Reward: 136.000000, Epsilon: 0.100000\n",
            "Game: 172, Total Reward: 137.000000, Epsilon: 0.100000\n",
            "Game: 173, Total Reward: 158.000000, Epsilon: 0.100000\n",
            "Game: 174, Total Reward: 163.000000, Epsilon: 0.100000\n",
            "Game: 175, Total Reward: 133.000000, Epsilon: 0.100000\n",
            "Game: 176, Total Reward: 132.000000, Epsilon: 0.100000\n",
            "Game: 177, Total Reward: 129.000000, Epsilon: 0.100000\n",
            "Game: 178, Total Reward: 172.000000, Epsilon: 0.100000\n",
            "Game: 179, Total Reward: 119.000000, Epsilon: 0.100000\n",
            "Game: 180, Total Reward: 127.000000, Epsilon: 0.100000\n",
            "Game: 181, Total Reward: 165.000000, Epsilon: 0.100000\n",
            "Game: 182, Total Reward: 316.000000, Epsilon: 0.100000\n",
            "Game: 183, Total Reward: 150.000000, Epsilon: 0.100000\n",
            "Game: 184, Total Reward: 127.000000, Epsilon: 0.100000\n",
            "Game: 185, Total Reward: 186.000000, Epsilon: 0.100000\n",
            "Game: 186, Total Reward: 112.000000, Epsilon: 0.100000\n",
            "Game: 187, Total Reward: 154.000000, Epsilon: 0.100000\n",
            "Game: 188, Total Reward: 147.000000, Epsilon: 0.100000\n",
            "Game: 189, Total Reward: 149.000000, Epsilon: 0.100000\n",
            "Game: 190, Total Reward: 145.000000, Epsilon: 0.100000\n",
            "Game: 191, Total Reward: 166.000000, Epsilon: 0.100000\n",
            "Game: 192, Total Reward: 150.000000, Epsilon: 0.100000\n",
            "Game: 193, Total Reward: 136.000000, Epsilon: 0.100000\n",
            "Game: 194, Total Reward: 151.000000, Epsilon: 0.100000\n",
            "Game: 195, Total Reward: 138.000000, Epsilon: 0.100000\n",
            "Game: 196, Total Reward: 152.000000, Epsilon: 0.100000\n",
            "Game: 197, Total Reward: 161.000000, Epsilon: 0.100000\n",
            "Game: 198, Total Reward: 140.000000, Epsilon: 0.100000\n",
            "Game: 199, Total Reward: 119.000000, Epsilon: 0.100000\n",
            "Game: 200, Total Reward: 124.000000, Epsilon: 0.100000\n",
            "Game: 1, Total Reward: 38.000000, Epsilon: 0.826565\n",
            "Game: 2, Total Reward: 47.000000, Epsilon: 0.653073\n",
            "Game: 3, Total Reward: 42.000000, Epsilon: 0.529092\n",
            "Game: 4, Total Reward: 10.000000, Epsilon: 0.503225\n",
            "Game: 5, Total Reward: 30.000000, Epsilon: 0.432967\n",
            "Game: 6, Total Reward: 10.000000, Epsilon: 0.411799\n",
            "Game: 7, Total Reward: 14.000000, Epsilon: 0.383891\n",
            "Game: 8, Total Reward: 14.000000, Epsilon: 0.357875\n",
            "Game: 9, Total Reward: 15.000000, Epsilon: 0.331954\n",
            "Game: 10, Total Reward: 10.000000, Epsilon: 0.315725\n",
            "Game: 11, Total Reward: 12.000000, Epsilon: 0.297294\n",
            "Game: 12, Total Reward: 13.000000, Epsilon: 0.278539\n",
            "Game: 13, Total Reward: 9.000000, Epsilon: 0.266252\n",
            "Game: 14, Total Reward: 10.000000, Epsilon: 0.253235\n",
            "Game: 15, Total Reward: 8.000000, Epsilon: 0.243281\n",
            "Game: 16, Total Reward: 9.000000, Epsilon: 0.232550\n",
            "Game: 17, Total Reward: 12.000000, Epsilon: 0.218974\n",
            "Game: 18, Total Reward: 12.000000, Epsilon: 0.206191\n",
            "Game: 19, Total Reward: 12.000000, Epsilon: 0.194154\n",
            "Game: 20, Total Reward: 11.000000, Epsilon: 0.183739\n",
            "Game: 21, Total Reward: 9.000000, Epsilon: 0.175634\n",
            "Game: 22, Total Reward: 9.000000, Epsilon: 0.167887\n",
            "Game: 23, Total Reward: 9.000000, Epsilon: 0.160481\n",
            "Game: 24, Total Reward: 12.000000, Epsilon: 0.151113\n",
            "Game: 25, Total Reward: 10.000000, Epsilon: 0.143725\n",
            "Game: 26, Total Reward: 9.000000, Epsilon: 0.137385\n",
            "Game: 27, Total Reward: 10.000000, Epsilon: 0.130668\n",
            "Game: 28, Total Reward: 13.000000, Epsilon: 0.122425\n",
            "Game: 29, Total Reward: 11.000000, Epsilon: 0.115858\n",
            "Game: 30, Total Reward: 27.000000, Epsilon: 0.101192\n",
            "Game: 31, Total Reward: 13.000000, Epsilon: 0.100000\n",
            "Game: 32, Total Reward: 26.000000, Epsilon: 0.100000\n",
            "Game: 33, Total Reward: 18.000000, Epsilon: 0.100000\n",
            "Game: 34, Total Reward: 12.000000, Epsilon: 0.100000\n",
            "Game: 35, Total Reward: 10.000000, Epsilon: 0.100000\n",
            "Game: 36, Total Reward: 12.000000, Epsilon: 0.100000\n",
            "Game: 37, Total Reward: 10.000000, Epsilon: 0.100000\n",
            "Game: 38, Total Reward: 10.000000, Epsilon: 0.100000\n",
            "Game: 39, Total Reward: 12.000000, Epsilon: 0.100000\n",
            "Game: 40, Total Reward: 12.000000, Epsilon: 0.100000\n",
            "Game: 41, Total Reward: 11.000000, Epsilon: 0.100000\n",
            "Game: 42, Total Reward: 217.000000, Epsilon: 0.100000\n",
            "Game: 43, Total Reward: 53.000000, Epsilon: 0.100000\n",
            "Game: 44, Total Reward: 13.000000, Epsilon: 0.100000\n",
            "Game: 45, Total Reward: 103.000000, Epsilon: 0.100000\n",
            "Game: 46, Total Reward: 62.000000, Epsilon: 0.100000\n",
            "Game: 47, Total Reward: 52.000000, Epsilon: 0.100000\n",
            "Game: 48, Total Reward: 72.000000, Epsilon: 0.100000\n",
            "Game: 49, Total Reward: 107.000000, Epsilon: 0.100000\n",
            "Game: 50, Total Reward: 41.000000, Epsilon: 0.100000\n",
            "Game: 51, Total Reward: 100.000000, Epsilon: 0.100000\n",
            "Game: 52, Total Reward: 90.000000, Epsilon: 0.100000\n",
            "Game: 53, Total Reward: 42.000000, Epsilon: 0.100000\n",
            "Game: 54, Total Reward: 49.000000, Epsilon: 0.100000\n",
            "Game: 55, Total Reward: 60.000000, Epsilon: 0.100000\n",
            "Game: 56, Total Reward: 75.000000, Epsilon: 0.100000\n",
            "Game: 57, Total Reward: 39.000000, Epsilon: 0.100000\n",
            "Game: 58, Total Reward: 54.000000, Epsilon: 0.100000\n",
            "Game: 59, Total Reward: 100.000000, Epsilon: 0.100000\n",
            "Game: 60, Total Reward: 99.000000, Epsilon: 0.100000\n",
            "Game: 61, Total Reward: 29.000000, Epsilon: 0.100000\n",
            "Game: 62, Total Reward: 42.000000, Epsilon: 0.100000\n",
            "Game: 63, Total Reward: 62.000000, Epsilon: 0.100000\n",
            "Game: 64, Total Reward: 43.000000, Epsilon: 0.100000\n",
            "Game: 65, Total Reward: 177.000000, Epsilon: 0.100000\n",
            "Game: 66, Total Reward: 115.000000, Epsilon: 0.100000\n",
            "Game: 67, Total Reward: 51.000000, Epsilon: 0.100000\n",
            "Game: 68, Total Reward: 84.000000, Epsilon: 0.100000\n",
            "Game: 69, Total Reward: 122.000000, Epsilon: 0.100000\n",
            "Game: 70, Total Reward: 79.000000, Epsilon: 0.100000\n",
            "Game: 71, Total Reward: 63.000000, Epsilon: 0.100000\n",
            "Game: 72, Total Reward: 52.000000, Epsilon: 0.100000\n",
            "Game: 73, Total Reward: 81.000000, Epsilon: 0.100000\n",
            "Game: 74, Total Reward: 86.000000, Epsilon: 0.100000\n",
            "Game: 75, Total Reward: 109.000000, Epsilon: 0.100000\n",
            "Game: 76, Total Reward: 60.000000, Epsilon: 0.100000\n",
            "Game: 77, Total Reward: 75.000000, Epsilon: 0.100000\n",
            "Game: 78, Total Reward: 95.000000, Epsilon: 0.100000\n",
            "Game: 79, Total Reward: 75.000000, Epsilon: 0.100000\n",
            "Game: 80, Total Reward: 175.000000, Epsilon: 0.100000\n",
            "Game: 81, Total Reward: 127.000000, Epsilon: 0.100000\n",
            "Game: 82, Total Reward: 184.000000, Epsilon: 0.100000\n",
            "Game: 83, Total Reward: 91.000000, Epsilon: 0.100000\n",
            "Game: 84, Total Reward: 338.000000, Epsilon: 0.100000\n",
            "Game: 85, Total Reward: 396.000000, Epsilon: 0.100000\n",
            "Game: 86, Total Reward: 175.000000, Epsilon: 0.100000\n",
            "Game: 87, Total Reward: 395.000000, Epsilon: 0.100000\n",
            "Game: 88, Total Reward: 203.000000, Epsilon: 0.100000\n",
            "Game: 89, Total Reward: 253.000000, Epsilon: 0.100000\n",
            "Game: 90, Total Reward: 164.000000, Epsilon: 0.100000\n",
            "Game: 91, Total Reward: 349.000000, Epsilon: 0.100000\n",
            "Game: 92, Total Reward: 244.000000, Epsilon: 0.100000\n",
            "Game: 93, Total Reward: 230.000000, Epsilon: 0.100000\n",
            "Game: 94, Total Reward: 189.000000, Epsilon: 0.100000\n",
            "Game: 95, Total Reward: 252.000000, Epsilon: 0.100000\n",
            "Game: 96, Total Reward: 487.000000, Epsilon: 0.100000\n",
            "Game: 97, Total Reward: 500.000000, Epsilon: 0.100000\n",
            "Game: 98, Total Reward: 203.000000, Epsilon: 0.100000\n",
            "Game: 99, Total Reward: 399.000000, Epsilon: 0.100000\n",
            "Game: 100, Total Reward: 210.000000, Epsilon: 0.100000\n",
            "Game: 101, Total Reward: 225.000000, Epsilon: 0.100000\n",
            "Game: 102, Total Reward: 291.000000, Epsilon: 0.100000\n",
            "Game: 103, Total Reward: 217.000000, Epsilon: 0.100000\n",
            "Game: 104, Total Reward: 251.000000, Epsilon: 0.100000\n",
            "Game: 105, Total Reward: 325.000000, Epsilon: 0.100000\n",
            "Game: 106, Total Reward: 349.000000, Epsilon: 0.100000\n",
            "Game: 107, Total Reward: 204.000000, Epsilon: 0.100000\n",
            "Game: 108, Total Reward: 243.000000, Epsilon: 0.100000\n",
            "Game: 109, Total Reward: 247.000000, Epsilon: 0.100000\n",
            "Game: 110, Total Reward: 190.000000, Epsilon: 0.100000\n",
            "Game: 111, Total Reward: 500.000000, Epsilon: 0.100000\n",
            "Game: 112, Total Reward: 200.000000, Epsilon: 0.100000\n",
            "Game: 113, Total Reward: 404.000000, Epsilon: 0.100000\n",
            "Game: 114, Total Reward: 243.000000, Epsilon: 0.100000\n",
            "Game: 115, Total Reward: 192.000000, Epsilon: 0.100000\n",
            "Game: 116, Total Reward: 278.000000, Epsilon: 0.100000\n",
            "Game: 117, Total Reward: 195.000000, Epsilon: 0.100000\n",
            "Game: 118, Total Reward: 212.000000, Epsilon: 0.100000\n",
            "Game: 119, Total Reward: 240.000000, Epsilon: 0.100000\n",
            "Game: 120, Total Reward: 227.000000, Epsilon: 0.100000\n",
            "Game: 121, Total Reward: 319.000000, Epsilon: 0.100000\n",
            "Game: 122, Total Reward: 223.000000, Epsilon: 0.100000\n",
            "Game: 123, Total Reward: 167.000000, Epsilon: 0.100000\n",
            "Game: 124, Total Reward: 276.000000, Epsilon: 0.100000\n",
            "Game: 125, Total Reward: 186.000000, Epsilon: 0.100000\n",
            "Game: 126, Total Reward: 193.000000, Epsilon: 0.100000\n",
            "Game: 127, Total Reward: 252.000000, Epsilon: 0.100000\n",
            "Game: 128, Total Reward: 178.000000, Epsilon: 0.100000\n",
            "Game: 129, Total Reward: 207.000000, Epsilon: 0.100000\n",
            "Game: 130, Total Reward: 314.000000, Epsilon: 0.100000\n",
            "Game: 131, Total Reward: 224.000000, Epsilon: 0.100000\n",
            "Game: 132, Total Reward: 235.000000, Epsilon: 0.100000\n",
            "Game: 133, Total Reward: 177.000000, Epsilon: 0.100000\n",
            "Game: 134, Total Reward: 234.000000, Epsilon: 0.100000\n",
            "Game: 135, Total Reward: 217.000000, Epsilon: 0.100000\n",
            "Game: 136, Total Reward: 215.000000, Epsilon: 0.100000\n",
            "Game: 137, Total Reward: 176.000000, Epsilon: 0.100000\n",
            "Game: 138, Total Reward: 323.000000, Epsilon: 0.100000\n",
            "Game: 139, Total Reward: 239.000000, Epsilon: 0.100000\n",
            "Game: 140, Total Reward: 192.000000, Epsilon: 0.100000\n",
            "Game: 141, Total Reward: 213.000000, Epsilon: 0.100000\n",
            "Game: 142, Total Reward: 277.000000, Epsilon: 0.100000\n",
            "Game: 143, Total Reward: 211.000000, Epsilon: 0.100000\n",
            "Game: 144, Total Reward: 204.000000, Epsilon: 0.100000\n",
            "Game: 145, Total Reward: 206.000000, Epsilon: 0.100000\n",
            "Game: 146, Total Reward: 266.000000, Epsilon: 0.100000\n",
            "Game: 147, Total Reward: 200.000000, Epsilon: 0.100000\n",
            "Game: 148, Total Reward: 237.000000, Epsilon: 0.100000\n",
            "Game: 149, Total Reward: 215.000000, Epsilon: 0.100000\n",
            "Game: 150, Total Reward: 241.000000, Epsilon: 0.100000\n",
            "Game: 151, Total Reward: 247.000000, Epsilon: 0.100000\n",
            "Game: 152, Total Reward: 244.000000, Epsilon: 0.100000\n",
            "Game: 153, Total Reward: 214.000000, Epsilon: 0.100000\n",
            "Game: 154, Total Reward: 344.000000, Epsilon: 0.100000\n",
            "Game: 155, Total Reward: 183.000000, Epsilon: 0.100000\n",
            "Game: 156, Total Reward: 212.000000, Epsilon: 0.100000\n",
            "Game: 157, Total Reward: 311.000000, Epsilon: 0.100000\n",
            "Game: 158, Total Reward: 212.000000, Epsilon: 0.100000\n",
            "Game: 159, Total Reward: 201.000000, Epsilon: 0.100000\n",
            "Game: 160, Total Reward: 251.000000, Epsilon: 0.100000\n",
            "Game: 161, Total Reward: 301.000000, Epsilon: 0.100000\n",
            "Game: 162, Total Reward: 176.000000, Epsilon: 0.100000\n",
            "Game: 163, Total Reward: 281.000000, Epsilon: 0.100000\n",
            "Game: 164, Total Reward: 329.000000, Epsilon: 0.100000\n",
            "Game: 165, Total Reward: 175.000000, Epsilon: 0.100000\n",
            "Game: 166, Total Reward: 221.000000, Epsilon: 0.100000\n",
            "Game: 167, Total Reward: 172.000000, Epsilon: 0.100000\n",
            "Game: 168, Total Reward: 239.000000, Epsilon: 0.100000\n",
            "Game: 169, Total Reward: 236.000000, Epsilon: 0.100000\n",
            "Game: 170, Total Reward: 418.000000, Epsilon: 0.100000\n",
            "Game: 171, Total Reward: 202.000000, Epsilon: 0.100000\n",
            "Game: 172, Total Reward: 250.000000, Epsilon: 0.100000\n",
            "Game: 173, Total Reward: 245.000000, Epsilon: 0.100000\n",
            "Game: 174, Total Reward: 196.000000, Epsilon: 0.100000\n",
            "Game: 175, Total Reward: 170.000000, Epsilon: 0.100000\n",
            "Game: 176, Total Reward: 410.000000, Epsilon: 0.100000\n",
            "Game: 177, Total Reward: 229.000000, Epsilon: 0.100000\n",
            "Game: 178, Total Reward: 212.000000, Epsilon: 0.100000\n",
            "Game: 179, Total Reward: 359.000000, Epsilon: 0.100000\n",
            "Game: 180, Total Reward: 208.000000, Epsilon: 0.100000\n",
            "Game: 181, Total Reward: 221.000000, Epsilon: 0.100000\n",
            "Game: 182, Total Reward: 265.000000, Epsilon: 0.100000\n",
            "Game: 183, Total Reward: 207.000000, Epsilon: 0.100000\n",
            "Game: 184, Total Reward: 198.000000, Epsilon: 0.100000\n",
            "Game: 185, Total Reward: 185.000000, Epsilon: 0.100000\n",
            "Game: 186, Total Reward: 332.000000, Epsilon: 0.100000\n",
            "Game: 187, Total Reward: 214.000000, Epsilon: 0.100000\n",
            "Game: 188, Total Reward: 239.000000, Epsilon: 0.100000\n",
            "Game: 189, Total Reward: 296.000000, Epsilon: 0.100000\n",
            "Game: 190, Total Reward: 245.000000, Epsilon: 0.100000\n",
            "Game: 191, Total Reward: 276.000000, Epsilon: 0.100000\n",
            "Game: 192, Total Reward: 269.000000, Epsilon: 0.100000\n",
            "Game: 193, Total Reward: 184.000000, Epsilon: 0.100000\n",
            "Game: 194, Total Reward: 275.000000, Epsilon: 0.100000\n",
            "Game: 195, Total Reward: 258.000000, Epsilon: 0.100000\n",
            "Game: 196, Total Reward: 221.000000, Epsilon: 0.100000\n",
            "Game: 197, Total Reward: 312.000000, Epsilon: 0.100000\n",
            "Game: 198, Total Reward: 225.000000, Epsilon: 0.100000\n",
            "Game: 199, Total Reward: 248.000000, Epsilon: 0.100000\n",
            "Game: 200, Total Reward: 184.000000, Epsilon: 0.100000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "y407lhtzeq3U",
        "outputId": "1c9ac88c-b0c0-4e22-bd48-a1d1ce3d1d69"
      },
      "source": [
        "\"\"\"\n",
        "class RainbowDQN:\n",
        "\n",
        "  def __init__(self, env, v_min=0, v_max=10, n_atoms=11, opt=None, loss=None, \n",
        "               batch_size=32, buffer_length=1_000_000, gamma=0.95, model=None,\n",
        "               update_freq=50, n_step=1, replay_freq=1, alpha=1, beta=1,\n",
        "               factorised=False):\n",
        "    self.env = env\n",
        "    self.obs_dim = env.observation_space.shape\n",
        "    self.act_dim = env.action_space.n\n",
        "    self.update_freq = update_freq\n",
        "    self.buffer = PERBuffer(max_len=buffer_length)\n",
        "    \n",
        "    self.batch_size = batch_size\n",
        "    self.gamma = gamma\n",
        "    self.n_step = n_step\n",
        "    self.v_min = v_min\n",
        "    self.v_max = v_max\n",
        "    self.n_atoms = n_atoms\n",
        "    self.dz = (v_max - v_min)/(n_atoms - 1)\n",
        "    self.z = np.array([v_min + i * self.dz for i in range(n_atoms)])\n",
        "    self.factorised = factorised\n",
        "    self.model = self.build_model(model)\n",
        "    self.target_model = self.build_model(model)\n",
        "    self.replay_freq = replay_freq\n",
        "    self.alpha = alpha\n",
        "    self.beta = beta\n",
        "    \n",
        "\n",
        "    if opt is None:\n",
        "      self.optimizer = tf.keras.optimizers.Adam()\n",
        "    else:\n",
        "      self.optimizer = opt\n",
        "\n",
        "    if loss is None:\n",
        "      self.loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "    else:\n",
        "      self.loss = loss\n",
        "  \n",
        "  def build_model(self, model):\n",
        "    if model is None:\n",
        "      inp = tf.keras.Input(self.obs_dim[0], dtype=\"float32\")\n",
        "      x = NoisyDense(24, self.obs_dim[0], activation=tf.keras.activations.relu, factorised=self.factorised)(inp)\n",
        "      x = NoisyDense(24, 24, activation=tf.keras.activations.relu, factorised=self.factorised)(x)\n",
        "      out = []\n",
        "      for i in range(self.n_atoms):\n",
        "        value = NoisyDense(1, 24, factorised=self.factorised)(x)\n",
        "        advantage = NoisyDense(self.act_dim, 24, factorised=self.factorised)(x)\n",
        "        out.append(Softmax()(value + advantage - tf.reduce_mean(advantage)))\n",
        "      return tf.keras.Model(inputs=inp, outputs=out) # [n_atoms, batch_size, act_dim]\n",
        "    else:\n",
        "      return model\n",
        "  \n",
        "  def act(self, x):\n",
        "    out = np.squeeze(np.array(self.model(x[np.newaxis, :])))\n",
        "    expected_values = np.dot(out.T, self.z)\n",
        "    return np.argmax(expected_values)\n",
        "  \n",
        "  def update_target(self):\n",
        "    self.target_model.set_weights(self.model.get_weights())\n",
        "  \n",
        "  def train(self, episodes): # TODO: try copying wasserstein onto output of the network instead of the whole one hot deal\n",
        "    total_steps = 0\n",
        "    for episode in range(episodes):\n",
        "      states = deque()\n",
        "      actions = deque()\n",
        "      rewards = deque()\n",
        "      states.append(self.env.reset())\n",
        "      rewards.append(0)\n",
        "      actions.append(0)\n",
        "      d = False\n",
        "      game_reward = 0\n",
        "      while not d:\n",
        "        for layer in self.model.layers:\n",
        "            if isinstance(layer, NoisyDense):\n",
        "              layer.unfreeze_epsilon()\n",
        "        a = self.act(states[-1])\n",
        "        for layer in self.model.layers:\n",
        "            if isinstance(layer, NoisyDense):\n",
        "              layer.freeze_epsilon()\n",
        "        s, r, d, _ = self.env.step(a)\n",
        "        game_reward += r\n",
        "        if len(states) == self.n_step:\n",
        "          self.compile_samples(states, actions, rewards, d)\n",
        "        self.push_observation(states, actions, rewards, s, a, r)\n",
        "        if total_steps % self.replay_freq == 0 and len(self.buffer.samples) >= self.batch_size:\n",
        "          samples, indices, probs = self.buffer.sample(self.batch_size)\n",
        "          #w_i = (1 / self.batch_size * 1 / probs) ** self.beta\n",
        "          #w_j = (self.batch_size * probs) ** -self.beta / np.amax(w_i)\n",
        "          m, actions_, states_ = self.wasserstein_metric(samples)\n",
        "          actions_one_hot = [np.zeros((self.batch_size, self.act_dim)) for i in range(self.n_atoms)]\n",
        "          for i in range(len(actions)):\n",
        "            for j in actions_one_hot:\n",
        "              j[i, actions[i]] = 1\n",
        "          self.backward(states_.astype('float32'), m, actions_one_hot)\n",
        "        if total_steps % self.update_freq == 0:\n",
        "          self.update_target()\n",
        "        total_steps += 1\n",
        "      print(\"Game: %d, Total Reward: %f\" % (episode + 1, game_reward))\n",
        "    \n",
        "  def backward(self, samples, m, actions):\n",
        "    with tf.GradientTape() as tape:\n",
        "      q = self.model(samples)\n",
        "      q_reduced = []\n",
        "      for i in range(len(q)):\n",
        "        q_reduced.append(tf.reduce_sum(q[i] * tf.constant(actions[i], dtype=\"float32\"), axis=1))\n",
        "      loss = self.loss(tf.stop_gradient(m), q_reduced)\n",
        "    grad = tape.gradient(loss, self.model.trainable_weights)\n",
        "    self.optimizer.apply_gradients(zip(grad, self.model.trainable_weights))\n",
        "\n",
        "  def compile_samples(self, states, actions, rewards, done):\n",
        "    S = states[0]\n",
        "    S1 = states[-1]\n",
        "    A = actions[0]\n",
        "    D = done\n",
        "    R = 0\n",
        "    for i in range(len(rewards)):\n",
        "      R += rewards[i] * (self.gamma ** i)\n",
        "    self.buffer.add(S, A, R, S1, D)\n",
        "  \n",
        "  def push_observation(self, states, actions, rewards, s, a, r):\n",
        "    states.append(s)\n",
        "    actions.append(a)\n",
        "    rewards.append(r)\n",
        "    if len(states) > self.n_step:\n",
        "      states.popleft()\n",
        "      actions.popleft()\n",
        "      rewards.popleft()\n",
        "  \n",
        "  def wasserstein_metric(self, samples):\n",
        "    states = np.array([i[0] for i in samples], dtype=np.float32)\n",
        "    actions = np.array([i[1] for i in samples])\n",
        "    rewards = np.array([i[2] for i in samples])\n",
        "    nexts = np.array([i[3] for i in samples])\n",
        "    dones = np.array([i[4] for i in samples])\n",
        "    m = [np.zeros((self.batch_size,), dtype=np.float32) for i in range(self.n_atoms)]\n",
        "    q = np.stack(self.target_model(nexts))\n",
        "    expected_values = np.zeros((self.batch_size, self.act_dim))\n",
        "    for b in range(self.batch_size):\n",
        "      for a in range(self.act_dim):\n",
        "        expected_values[b, a] = np.dot(self.z, q[:, b, a])\n",
        "    a_star = np.argmax(expected_values, axis=1)\n",
        "    for i in range(len(states)):\n",
        "      if dones[i]:\n",
        "        Tz = max(self.v_min, min(self.v_max, rewards[i]))\n",
        "        b_j = (Tz - self.v_min) / self.dz\n",
        "        l = math.floor(b_j)\n",
        "        u = math.ceil(b_j)\n",
        "        m[int(l)][i] += (u - b_j)\n",
        "        m[int(u)][i] += (b_j - l)\n",
        "      else:\n",
        "        for j in range(len(self.z)):\n",
        "          Tz = max(self.v_min, min(self.v_max, rewards[i] + (self.gamma ** self.n_step) * self.z[j]))\n",
        "          b_j = (Tz - self.v_min) / self.dz\n",
        "          l = math.floor(b_j)\n",
        "          u = math.ceil(b_j)\n",
        "          m[int(l)][i] += q[j, i, a_star[i]] * (u - b_j)\n",
        "          m[int(u)][i] += q[j, i, a_star[i]] * (b_j - l)\n",
        "    return m, actions, states\n",
        "        \n",
        "dqn = RainbowDQN(gym.make(\"CartPole-v1\"), n_step=5, replay_freq=1, n_atoms=5, v_max=4)\n",
        "dqn.train(500) \n",
        "#print(np.array(dqn.model(np.ones((10, 4)))).shape)\n",
        "\"\"\""
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nclass RainbowDQN:\\n\\n  def __init__(self, env, v_min=0, v_max=10, n_atoms=11, opt=None, loss=None, \\n               batch_size=32, buffer_length=1_000_000, gamma=0.95, model=None,\\n               update_freq=50, n_step=1, replay_freq=1, alpha=1, beta=1,\\n               factorised=False):\\n    self.env = env\\n    self.obs_dim = env.observation_space.shape\\n    self.act_dim = env.action_space.n\\n    self.update_freq = update_freq\\n    self.buffer = PERBuffer(max_len=buffer_length)\\n    \\n    self.batch_size = batch_size\\n    self.gamma = gamma\\n    self.n_step = n_step\\n    self.v_min = v_min\\n    self.v_max = v_max\\n    self.n_atoms = n_atoms\\n    self.dz = (v_max - v_min)/(n_atoms - 1)\\n    self.z = np.array([v_min + i * self.dz for i in range(n_atoms)])\\n    self.factorised = factorised\\n    self.model = self.build_model(model)\\n    self.target_model = self.build_model(model)\\n    self.replay_freq = replay_freq\\n    self.alpha = alpha\\n    self.beta = beta\\n    \\n\\n    if opt is None:\\n      self.optimizer = tf.keras.optimizers.Adam()\\n    else:\\n      self.optimizer = opt\\n\\n    if loss is None:\\n      self.loss = tf.keras.losses.CategoricalCrossentropy()\\n    else:\\n      self.loss = loss\\n  \\n  def build_model(self, model):\\n    if model is None:\\n      inp = tf.keras.Input(self.obs_dim[0], dtype=\"float32\")\\n      x = NoisyDense(24, self.obs_dim[0], activation=tf.keras.activations.relu, factorised=self.factorised)(inp)\\n      x = NoisyDense(24, 24, activation=tf.keras.activations.relu, factorised=self.factorised)(x)\\n      out = []\\n      for i in range(self.n_atoms):\\n        value = NoisyDense(1, 24, factorised=self.factorised)(x)\\n        advantage = NoisyDense(self.act_dim, 24, factorised=self.factorised)(x)\\n        out.append(Softmax()(value + advantage - tf.reduce_mean(advantage)))\\n      return tf.keras.Model(inputs=inp, outputs=out) # [n_atoms, batch_size, act_dim]\\n    else:\\n      return model\\n  \\n  def act(self, x):\\n    out = np.squeeze(np.array(self.model(x[np.newaxis, :])))\\n    expected_values = np.dot(out.T, self.z)\\n    return np.argmax(expected_values)\\n  \\n  def update_target(self):\\n    self.target_model.set_weights(self.model.get_weights())\\n  \\n  def train(self, episodes): # TODO: try copying wasserstein onto output of the network instead of the whole one hot deal\\n    total_steps = 0\\n    for episode in range(episodes):\\n      states = deque()\\n      actions = deque()\\n      rewards = deque()\\n      states.append(self.env.reset())\\n      rewards.append(0)\\n      actions.append(0)\\n      d = False\\n      game_reward = 0\\n      while not d:\\n        for layer in self.model.layers:\\n            if isinstance(layer, NoisyDense):\\n              layer.unfreeze_epsilon()\\n        a = self.act(states[-1])\\n        for layer in self.model.layers:\\n            if isinstance(layer, NoisyDense):\\n              layer.freeze_epsilon()\\n        s, r, d, _ = self.env.step(a)\\n        game_reward += r\\n        if len(states) == self.n_step:\\n          self.compile_samples(states, actions, rewards, d)\\n        self.push_observation(states, actions, rewards, s, a, r)\\n        if total_steps % self.replay_freq == 0 and len(self.buffer.samples) >= self.batch_size:\\n          samples, indices, probs = self.buffer.sample(self.batch_size)\\n          #w_i = (1 / self.batch_size * 1 / probs) ** self.beta\\n          #w_j = (self.batch_size * probs) ** -self.beta / np.amax(w_i)\\n          m, actions_, states_ = self.wasserstein_metric(samples)\\n          actions_one_hot = [np.zeros((self.batch_size, self.act_dim)) for i in range(self.n_atoms)]\\n          for i in range(len(actions)):\\n            for j in actions_one_hot:\\n              j[i, actions[i]] = 1\\n          self.backward(states_.astype(\\'float32\\'), m, actions_one_hot)\\n        if total_steps % self.update_freq == 0:\\n          self.update_target()\\n        total_steps += 1\\n      print(\"Game: %d, Total Reward: %f\" % (episode + 1, game_reward))\\n    \\n  def backward(self, samples, m, actions):\\n    with tf.GradientTape() as tape:\\n      q = self.model(samples)\\n      q_reduced = []\\n      for i in range(len(q)):\\n        q_reduced.append(tf.reduce_sum(q[i] * tf.constant(actions[i], dtype=\"float32\"), axis=1))\\n      loss = self.loss(tf.stop_gradient(m), q_reduced)\\n    grad = tape.gradient(loss, self.model.trainable_weights)\\n    self.optimizer.apply_gradients(zip(grad, self.model.trainable_weights))\\n\\n  def compile_samples(self, states, actions, rewards, done):\\n    S = states[0]\\n    S1 = states[-1]\\n    A = actions[0]\\n    D = done\\n    R = 0\\n    for i in range(len(rewards)):\\n      R += rewards[i] * (self.gamma ** i)\\n    self.buffer.add(S, A, R, S1, D)\\n  \\n  def push_observation(self, states, actions, rewards, s, a, r):\\n    states.append(s)\\n    actions.append(a)\\n    rewards.append(r)\\n    if len(states) > self.n_step:\\n      states.popleft()\\n      actions.popleft()\\n      rewards.popleft()\\n  \\n  def wasserstein_metric(self, samples):\\n    states = np.array([i[0] for i in samples], dtype=np.float32)\\n    actions = np.array([i[1] for i in samples])\\n    rewards = np.array([i[2] for i in samples])\\n    nexts = np.array([i[3] for i in samples])\\n    dones = np.array([i[4] for i in samples])\\n    m = [np.zeros((self.batch_size,), dtype=np.float32) for i in range(self.n_atoms)]\\n    q = np.stack(self.target_model(nexts))\\n    expected_values = np.zeros((self.batch_size, self.act_dim))\\n    for b in range(self.batch_size):\\n      for a in range(self.act_dim):\\n        expected_values[b, a] = np.dot(self.z, q[:, b, a])\\n    a_star = np.argmax(expected_values, axis=1)\\n    for i in range(len(states)):\\n      if dones[i]:\\n        Tz = max(self.v_min, min(self.v_max, rewards[i]))\\n        b_j = (Tz - self.v_min) / self.dz\\n        l = math.floor(b_j)\\n        u = math.ceil(b_j)\\n        m[int(l)][i] += (u - b_j)\\n        m[int(u)][i] += (b_j - l)\\n      else:\\n        for j in range(len(self.z)):\\n          Tz = max(self.v_min, min(self.v_max, rewards[i] + (self.gamma ** self.n_step) * self.z[j]))\\n          b_j = (Tz - self.v_min) / self.dz\\n          l = math.floor(b_j)\\n          u = math.ceil(b_j)\\n          m[int(l)][i] += q[j, i, a_star[i]] * (u - b_j)\\n          m[int(u)][i] += q[j, i, a_star[i]] * (b_j - l)\\n    return m, actions, states\\n        \\ndqn = RainbowDQN(gym.make(\"CartPole-v1\"), n_step=5, replay_freq=1, n_atoms=5, v_max=4)\\ndqn.train(500) \\n#print(np.array(dqn.model(np.ones((10, 4)))).shape)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-UuYpTz4_z2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "outputId": "95fe053c-67be-4eee-8447-448f6e895d15"
      },
      "source": [
        "arr = np.array([1, 2, 3, 4, 5])\n",
        "print(arr[np.newaxis, :].shape)\n",
        "V_MIN = 0\n",
        "V_MAX = 10\n",
        "DZ = 1\n",
        "N_ATOMS = 6\n",
        "BATCH_SIZE = 5\n",
        "GAMMA = 0.5\n",
        "ACTIONS = 2\n",
        "\n",
        "\n",
        "rewards = np.random.randint(0, 10, size=(BATCH_SIZE,))\n",
        "dones = np.random.randint(0, 2, size=(BATCH_SIZE,))\n",
        "actions = np.random.randint(0, ACTIONS, size=(BATCH_SIZE,))\n",
        "dones_stacked = np.vstack([dones for _ in range(N_ATOMS)]).T\n",
        "z = np.array([1, 2, 3, 4, 5, 6])\n",
        "in_between = (1 - dones_stacked) * GAMMA * z\n",
        "Tz = in_between + rewards[:, np.newaxis]\n",
        "Tz = np.maximum(V_MIN, np.minimum(V_MAX, Tz))\n",
        "bj = (Tz - V_MIN) / DZ\n",
        "l = np.floor(bj)\n",
        "u = np.ceil(bj)\n",
        "#m_prob = np.array([np.zeros((BATCH_SIZE, N_ATOMS)) for _ in range(ACTIONS)])\n",
        "#m_prob[actions.reshape(BATCH_SIZE, 1), :, l.astype(int)] += (u - bj)\n",
        "m_prob = np.arange(ACTIONS * BATCH_SIZE * N_ATOMS).reshape((ACTIONS, BATCH_SIZE, N_ATOMS))\n",
        "print(m_prob)\n",
        "print(actions)\n",
        "print(l)\n",
        "print(m_prob[actions.reshape(BATCH_SIZE, 1), :, l.astype(int)])\n",
        "print(u - bj)\n",
        "\n",
        "# One 6, row of u - bj should be added to each 5x6 matrix of m_prob[...]\n",
        "# In other words, (u - bj)[i, j] gets added to m_prob[...][j, :, i]\n",
        "# To test, compare to the for-loop algorithm\n",
        "\n",
        "\"\"\"\n",
        "print(\"rewards:\", rewards)\n",
        "print(\"dones:\", dones)\n",
        "print(\"actions:\", actions)\n",
        "print(\"z:\", z)\n",
        "print(\"in_between:\", in_between)\n",
        "print(\"Tz:\", Tz)\n",
        "print(\"bj:\", bj)\n",
        "print(\"l:\", l)\n",
        "print(\"u:\", u)\n",
        "\"\"\"\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 5)\n",
            "[[[ 0  1  2  3  4  5]\n",
            "  [ 6  7  8  9 10 11]\n",
            "  [12 13 14 15 16 17]\n",
            "  [18 19 20 21 22 23]\n",
            "  [24 25 26 27 28 29]]\n",
            "\n",
            " [[30 31 32 33 34 35]\n",
            "  [36 37 38 39 40 41]\n",
            "  [42 43 44 45 46 47]\n",
            "  [48 49 50 51 52 53]\n",
            "  [54 55 56 57 58 59]]]\n",
            "[0 1 0 1 1]\n",
            "[[ 8.  8.  8.  8.  8.  8.]\n",
            " [ 5.  5.  5.  5.  5.  5.]\n",
            " [ 4.  5.  5.  6.  6.  7.]\n",
            " [ 7.  8.  8.  9.  9. 10.]\n",
            " [ 5.  5.  5.  5.  5.  5.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-9053bf215630>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_prob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 8 is out of bounds for axis 2 with size 6"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Y2wTKei4ujO",
        "outputId": "ebcd5e3f-acfc-426e-c836-20601e0323e3"
      },
      "source": [
        "arr = np.random.randint(0, 11, size=(5, 10))\n",
        "print(arr)\n",
        "print(arr[np.array([[0, 1, 3, 4],[0, 1, 3, 4]]), np.array([[0, 0, 0, 0],[1, 1, 1, 1]])])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[10  8  3  6  1 10 10  4  5  5]\n",
            " [ 9  9  6  0  4  6  1  8  3  9]\n",
            " [ 4  3  8  8  3  2  5  8 10  7]\n",
            " [10  8  2 10  5  0  7 10  9  0]\n",
            " [ 2  4  2  7  8  5  5  4  7  7]]\n",
            "[[10  9 10  2]\n",
            " [ 8  9  8  4]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVtXt0OKBC6G"
      },
      "source": [
        "v_min = 0\n",
        "v_max = 5\n",
        "n_atoms = 6\n",
        "i = 2\n",
        "dz = 1\n",
        "z = np.array([0, 1, 2, 3, 4, 5]) # self.z\n",
        "Z = [np.random.randint(0, 5, size=(10, 6)) for _ in range(2)] # z\n",
        "next_actions = np.array([0, 1, 1, 0, 1, 1, 1, 0, 0, 1])\n",
        "gamma = 0.5\n",
        "m_prob = np.zeros((2, 10, 6))\n",
        "actions = np.array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0])\n",
        "rewards = np.array([5, 6, 2, 3, 4, 5, 0, 9, 8, 2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNnY1WF5gULR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8285ba9b-b834-453c-8075-47b07afa1af4"
      },
      "source": [
        "%%time\n",
        "for j in range(n_atoms):\n",
        "  Tz = min(v_max, max(v_min, rewards[i] + gamma * z[j]))\n",
        "  bj = (Tz - v_min) / dz\n",
        "  l, u = math.floor(bj), math.ceil(bj)\n",
        "  m_prob[actions[i]][i][int(l)] += Z[next_actions[i]][i][j] * (u - bj)\n",
        "  m_prob[actions[i]][i][int(u)] += Z[next_actions[i]][i][j] * (bj - l)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 202 s, sys: 0 ns, total: 202 s\n",
            "Wall time: 211 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkLnNxZ-XyJB",
        "outputId": "cfe0929f-b852-4ba6-bf0a-08a0e58966dc"
      },
      "source": [
        "%%time\n",
        "Tz = np.minimum(v_max, np.maximum(v_min, rewards[i] + gamma * z))\n",
        "bj = (Tz - v_min) / dz\n",
        "l = np.floor(bj)\n",
        "u = np.ceil(bj)\n",
        "np.add.at(m_prob, (actions[i], i, l.astype(int)), Z[next_actions[i]][i] * (u - bj))\n",
        "np.add.at(m_prob, (actions[i], i, u.astype(int)), Z[next_actions[i]][i] * (bj - l))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 351 s, sys: 0 ns, total: 351 s\n",
            "Wall time: 245 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gqSeZfMbHZL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d914434-be02-484f-c8f2-43d27165c717"
      },
      "source": [
        "tensor = tf.constant([1, 2, 3, 4, 5])\n",
        "tensor.numpy()[0] = 10\n",
        "print(tensor)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([1 2 3 4 5], shape=(5,), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeBe2fJ-zQO6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e808e9a-80ad-4bc2-8bcf-61ff3bd33c13"
      },
      "source": [
        "arr1 = np.random.randint(low=0, high=3, size=(5, 2))\n",
        "arr2 = np.random.randint(low=0, high=3, size=(5,))\n",
        "print(arr1)\n",
        "print(arr2)\n",
        "print(np.dot(arr1.T, arr2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 2]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [2 2]\n",
            " [0 1]]\n",
            "[1 0 0 1 0]\n",
            "[3 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJuiZ1iMlv1N",
        "outputId": "55fa9d4d-72de-40d4-affc-32720a95b9c3"
      },
      "source": [
        "arr = np.array([np.random.randint(0, 3, size=(10, 2)) for i in range(5)])\n",
        "z = np.array([1, 2, 3, 4, 5])\n",
        "print(arr.shape)\n",
        "d = np.dot(arr.T, z)\n",
        "expected_values = np.zeros((10, 2))\n",
        "for b in range(10):\n",
        "  for a in range(2):\n",
        "    expected_values[b, a] = np.dot(arr[:, b, a], z)\n",
        "print(expected_values.shape)\n",
        "print(np.argmax(expected_values, axis=1).shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5, 10, 2)\n",
            "(10, 2)\n",
            "(10,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1-vFNwt02la",
        "outputId": "6230ebfb-3510-45d9-feca-7183c1cfc814"
      },
      "source": [
        "arr = [np.random.randint((4, 2)) for i in range(5)]\n",
        "oh = [np.array([[0, 1], [1, 0], [0, 1], [1, 0]]) for i in range(5)]\n",
        "# 5, 4, 2 -> 5, 4\n",
        "#print([i for i in arr])\n",
        "print([arr[i] * oh[i] for i in range(5)])\n",
        "arr2 = [arr[i] * oh[i] for i in range(5)]\n",
        "arr3 = []\n",
        "for i in range(len(arr2)):\n",
        "  arr3.append(np.sum(arr2[i], axis=1))\n",
        "print(arr3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([[0, 0],\n",
            "       [2, 0],\n",
            "       [0, 0],\n",
            "       [2, 0]]), array([[0, 0],\n",
            "       [3, 0],\n",
            "       [0, 0],\n",
            "       [3, 0]]), array([[0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0]]), array([[0, 0],\n",
            "       [3, 0],\n",
            "       [0, 0],\n",
            "       [3, 0]]), array([[0, 1],\n",
            "       [2, 0],\n",
            "       [0, 1],\n",
            "       [2, 0]])]\n",
            "[array([0, 2, 0, 2]), array([0, 3, 0, 3]), array([1, 1, 1, 1]), array([0, 3, 0, 3]), array([1, 2, 1, 2])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8tD95FbcFsb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}